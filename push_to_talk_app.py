import asyncio
import base64
import sounddevice as sd
import wave
import queue
import sys
import json
import os
from google.cloud import speech
from openai import AsyncOpenAI
from audio_util import AudioPlayerAsync, CHANNELS, SAMPLE_RATE
import functools
import time
print = functools.partial(print, flush=True)
# Load command configuration
with open("ray_conversation.json", encoding="utf-8") as f:
    cfg = json.load(f)["Kor"]


VOICE = "ash"

# Google STT ì¸ì¦ ì •ë³´ ì„¤ì •
credential_path = "path/to/your/google-credentials.json"
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credential_path

# ì‹¤ì‹œê°„ ë§ˆì´í¬ ì…ë ¥ â†’ Google STTë¡œ streaming
async def stream_stt_to_gpt(timeout_sec: float = 5.0):
    """
    timeout_sec ì´ˆ ì•ˆì— ìµœì¢… STT ê²°ê³¼(final_text)ë¥¼ ëª» ì–»ìœ¼ë©´
    ë¹ˆ ë¬¸ìì—´ì„ ë¦¬í„´í•˜ê³  ì¦‰ì‹œ ì¢…ë£Œí•©ë‹ˆë‹¤.
    """
    q_audio = queue.Queue()
    recording_done = asyncio.Event()

    def callback(indata, frames, time_info, status):
        if status:
            print(f"[ì˜¤ë””ì˜¤ ìƒíƒœ] {status}", file=sys.stderr, flush=True)
        q_audio.put(bytes(indata))
        
    # âœ… ë§ˆì´í¬ ì¥ì¹˜ ìë™ íƒìƒ‰
    input_device_index = None
    for idx, dev in enumerate(sd.query_devices()):
        if dev['max_input_channels'] > 0:
            input_device_index = idx
            break

    if input_device_index is None:
        print("[ì˜¤ë¥˜] ì…ë ¥ ê°€ëŠ¥í•œ ë§ˆì´í¬ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
        return ""

    device_info = sd.query_devices(input_device_index, 'input')
    SAMPLE_RATE = int(device_info['default_samplerate'])

    client = speech.SpeechClient()
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=SAMPLE_RATE,
        language_code="ko-KR",
    )
    streaming_config = speech.StreamingRecognitionConfig(
        config=config,
        interim_results=True,
        single_utterance=True,
    )

    def audio_generator():
        while not recording_done.is_set():
            chunk = q_audio.get()
            if chunk is None:
                break
            yield speech.StreamingRecognizeRequest(audio_content=chunk)
        # ìŠ¤íŠ¸ë¦¼ì„ ëë‚´ê¸° ìœ„í•œ ë¹ˆ ì²­í¬
        yield speech.StreamingRecognizeRequest(audio_content=b"")

    start_time = time.time()
    final_text = ""

    with sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=CHANNELS,
        dtype="int16",
        callback=callback
    ):
        print("ğŸ™ï¸ ë§í•˜ì„¸ìš”", file=sys.stderr, flush=True)
        responses = client.streaming_recognize(streaming_config, audio_generator())

        for response in responses:
                               
            for result in response.results:
                transcript = result.alternatives[0].transcript
                start_time = time.time()
                if result.is_final:
                    final_text += transcript
                    print(f"[âœ… ìµœì¢… ì¸ì‹ ê²°ê³¼] {final_text}", file=sys.stderr, flush=True)
                    recording_done.set()
                    return final_text
                else:
                    print(f"[ğŸ“ ì¤‘ê°„ ì¸ì‹] {transcript}", file=sys.stderr, flush=True)
            # íƒ€ì´ë¨¸ ì²´í¬
            if time.time() - start_time > timeout_sec:
                print(f"[STT] íƒ€ì„ì•„ì›ƒ({timeout_sec}s) ë°œìƒ, ì¬ì‹œì‘í•©ë‹ˆë‹¤.", file=sys.stderr, flush=True)
                break

    # ì—¬ê¸°ê¹Œì§€ ì˜¤ë©´ (timeout ì´ê±°ë‚˜ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ)
    return final_text  # ë¹ˆ ë¬¸ìì—´ì´ë©´ ëˆ„êµ°ê°€ ë‹¤ì‹œ í˜¸ì¶œí•˜ë©´ ë˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ë¶€ë¶„ ê²°ê³¼

# ì‚¬ìš©ì ëª…ë ¹ í‚¤ì›Œë“œ ë¶„ê¸°
def match_command(text: str):
    for cmd, keywords in cfg["conditions"].items():
        if all(kw in text for kw in keywords):
            return cmd
    return None

# ì»¤ìŠ¤í…€ ì‹œí€€ìŠ¤ ì‹¤í–‰ í•¨ìˆ˜ë“¤
def exit_sequence():
    print(f"[ì»¤ë§¨ë“œ ì‘ë‹µ] {cfg['responses']['QUIT_PROGRAM']}")

def sing_sequence():
    print(f"[ì»¤ë§¨ë“œ ì‘ë‹µ] {cfg['responses']['SING_A_SONG']}")

def introduce_sequence():
    print(f"[ì»¤ë§¨ë“œ ì‘ë‹µ] {cfg['responses']['INTRODUCE']}")

def kidding_sequence():
    print(f"[ì»¤ë§¨ë“œ ì‘ë‹µ] {cfg['responses']['Kidding']}")

def weather_sequence():
    print(f"[ì»¤ë§¨ë“œ ì‘ë‹µ] {cfg['responses']['weather']}")

SEQUENCE_FUNCS = {
    "QUIT_PROGRAM": exit_sequence,
    "SING_A_SONG": sing_sequence,
    "INTRODUCE": introduce_sequence,
    "Kidding": kidding_sequence,
    "weather": weather_sequence,
}

# GPT Realtime APIë¡œ í…ìŠ¤íŠ¸ ì „ì†¡ í›„ ìŒì„± ì‘ë‹µ ë°›ê¸°
async def send_to_gpt(text):
    client = AsyncOpenAI(api_key = "openai_api_key") # ì—¬ê¸°ì— OpenAI API í‚¤ ì…ë ¥
    async with client.beta.realtime.connect(model="gpt-4o-realtime-preview") as conn:
        await conn.session.update(session={
            "instructions": "ë„ˆëŠ” ì• ë‹ˆë§¤íŠ¸ë¡œë‹‰ìŠ¤ ë¡œë´‡ì´ì•¼. ë„ˆì˜ ì´ë¦„ì€ ë ˆì´ì•¼. ë‚´ê°€ ë¬¼ì–´ë³´ëŠ” ê²ƒë“¤ì— ëŒ€í•´ ì˜ ëŒ€ë‹µí•´ì¤˜",
            "modalities": ["text", "audio"],
            #"turn_detection": {"type": "server_vad"},
            "voice": VOICE
        })
        print("[ì „ì†¡í•  í…ìŠ¤íŠ¸]", text)
        await conn.conversation.item.create(item={
            "type": "message",
            "role": "user",
            "content": [{"type": "input_text", "text": text}]
        })
        await conn.response.create()

        with wave.open("output.wav", "wb") as wf:
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(2)
            wf.setframerate(SAMPLE_RATE)
            accumulated_transcripts = {}  # item_idë³„ë¡œ ëˆ„ì í•  partial transcript
            answer_done = asyncio.Event()
            async for event in conn:
                # ì„¸ì…˜ ìƒì„±
                if event.type == "session.created":
                    print(f"ì„¸ì…˜ ìƒì„± ì™„ë£Œ: {event.session.id}")

                # ëª¨ë¸ì˜ ì˜¤ë””ì˜¤ ì‘ë‹µ (ë¶€ë¶„)
                elif event.type == "response.audio.delta":
                    # ì˜¤ë””ì˜¤ ì¬ìƒ
                    bytes_data = base64.b64decode(event.delta)
                    #ë°”ë¡œ ì¬ìƒì•ˆì‹œí‚¬ë ¤ë©´, ì£¼ì„ ì²˜ë¦¬
                    #audio_player.add_data(bytes_data)
                    
                    #wav íŒŒì¼ ì¬ìƒ
                    wf.writeframes(bytes_data)

                # ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ì‘ë‹µ (ë¶€ë¶„)
                elif event.type == "response.audio_transcript.delta":
                    # ì—¬ê¸°ì„œëŠ” ë¶€ë¶„ ìë§‰ë§Œ ëˆ„ì  (ì¦‰ì‹œ print X)
                    accumulated_transcripts[event.item_id] = (
                        accumulated_transcripts.get(event.item_id, "") + event.delta
                    )

                # ìµœì¢… ìë§‰ì´ ì™„ì„±ë˜ì—ˆë‹¤ê³  ì•Œë ¤ì£¼ëŠ” ì´ë²¤íŠ¸ (ê°€ì •)
                elif event.type == "response.audio_transcript.done":
                    # ì™„ì„±ëœ ìë§‰ë§Œ ì¶œë ¥
                    final_text = accumulated_transcripts.get(event.item_id, "")
                    print(f"[ì™„ì„±ë³¸] {final_text}")
                    # í˜¹ì‹œ ë‹¤ìŒ ì•„ì´í…œì—ì„œ ì¬ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ì •ë¦¬
                    accumulated_transcripts.pop(event.item_id, None)

                    # ì¢…ë£Œ ì‹ í˜¸ ì„¸íŠ¸
                    answer_done.set()

                elif event.type == "response.audio.done":
                    print("[Info] GPT ë‹µë³€(ìŒì„±)ì´ ëª¨ë‘ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    # ìë§‰ì´ ë‹¤ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
                    try:
                        await asyncio.wait_for(answer_done.wait(), timeout=3.0)
                    except asyncio.TimeoutError:
                        print("[âš ï¸ Warning] ìë§‰ ì‘ë‹µì´ 2ì´ˆ ì•ˆì— ì˜¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê·¸ëƒ¥ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    
                    
                    

                    # WAV íŒŒì¼ ë‹«ê¸°
                    wf.close()
                    
                    await conn.close()  # ëª…ì‹œì ìœ¼ë¡œ ì—°ê²° ë‹«ê¸°
                    #break    

                    

def print_and_exit(msg, code=0):
    # ë©”ì‹œì§€ ì¶œë ¥ í›„ ì¢…ë£Œ
    print(msg)
    sys.exit(code)

async def main():
    if len(sys.argv) < 2:
        print_and_exit("ì‚¬ìš©ë²•: python push_to_talk_app.py [sleep|active]", 1)
    mode = sys.argv[1]
    if mode == "sleep":
        # Sleep ëª¨ë“œ: "ë ˆì´" í‚¤ì›Œë“œ ëŒ€ê¸°
        while True:
            # STT ì½”ë£¨í‹´ì„ ë³„ë„ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰
            task = asyncio.create_task(stream_stt_to_gpt())
            try:
                user_text = await asyncio.wait_for(task, timeout= 5)
            except asyncio.TimeoutError:
                # ì¼ì • ì‹œê°„ ìŒì„± ì…ë ¥ ì—†ìœ¼ë©´ ê³„ì† sleep
                print("Time out again recording", file= sys.stderr, flush=True)
                
                task.cancel()
                
                try:
                    await task
                except asyncio.CancelledError:
                    pass

                continue

            if "ë ˆì´" in user_text:
                print("awake", flush=True)
                sys.exit(0)

            

    elif mode == "active":
        # Active ëª¨ë“œ: ìµœëŒ€ 3íšŒ, ê° 5ì´ˆê°„ STT ëŒ€ê¸°
        user_text = ""
        for attempt in range(3):
            try:
                user_text = await asyncio.wait_for(stream_stt_to_gpt(timeout_sec=5.0), timeout=5.5)
                # timeout_secì™€ wait_for íƒ€ì„ì•„ì›ƒì€ ê±°ì˜ ê°™ê²Œ ì„¤ì •í•˜ì„¸ìš”
            except asyncio.TimeoutError:
                print(f"[STT] {attempt+1}ë²ˆì§¸ íƒ€ì„ì•„ì›ƒ(5s)", file=sys.stderr, flush=True)
                continue
            if user_text :
                break  # ì¼ë‹¨ í•œ ë²ˆì´ë¼ë„ ìŒì„±ì´ ë“¤ì–´ì˜¤ë©´ ë£¨í”„ ì¢…ë£Œ

        # 3íšŒ ëª¨ë‘ íƒ€ì„ì•„ì›ƒ í–ˆìœ¼ë©´ sleep ë³µê·€
        if not user_text:
            print("sleep", flush=True)
            sys.exit(0)

        # ë“¤ì–´ì˜¨ í…ìŠ¤íŠ¸ê°€ ì¢…ë£Œ/ë…¸ë˜ í‚¤ì›Œë“œë©´ ë°”ë¡œ ë¦¬í„´
        if any(kw in user_text for kw in cfg["conditions"].get("QUIT_PROGRAM", [])):
            print("sleep", flush=True)
            sys.exit(0)
        if any(kw in user_text for kw in cfg["conditions"].get("SING_A_SONG", [])):
            print(user_text + "\n", end="", flush=True)
            print("singing", flush=True)
            sys.exit(0)

        # ì¼ë°˜ ëŒ€í™” â†’ GPT ì²˜ë¦¬
        await send_to_gpt(user_text)
        # GPT ëŒ€í™” ëë‚˜ë©´ ë‹¤ì‹œ main() ìœ¼ë¡œ ì˜¬ë¼ì™€ì„œ sleep/active ì¬íŒë‹¨

    else:
        print_and_exit(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ: {mode}", 1)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.", file=sys.stderr, flush=True)
        sys.exit(0)
