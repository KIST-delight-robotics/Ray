from collections import deque
import math
import os
import sys
import time
import json
import queue
import base64
import logging
import asyncio
import threading
import numpy as np
from abc import ABC, abstractmethod

from led import strip, led_set_dual
from rpi5_ws2812.ws2812 import Color

from conversation_manager import ConversationManager
from offline_motion import offline_motion_generation

from audio_processor import VADProcessor, SmartTurnProcessor, GoogleSTTStreamer, MicrophoneStream, find_input_device

from config import (
    SMART_TURN_MODEL_PATH,
    TURN_END_SILENCE_CHUNKS,
    MAX_TURN_CHUNKS,
    SMART_TURN_GRACE_PERIOD,
    STT_WAIT_TIMEOUT_SECONDS,
    SLEEP_FILE, AWAKE_FILE, ACTIVE_SESSION_TIMEOUT, START_KEYWORD, END_KEYWORDS,
    TTS_MODEL, VOICE, RESPONSES_MODEL, RESPONSES_PRESETS, AUDIO_CONFIG, ASSETS_DIR, OPENAI_API_KEY,
    RAG_PERSIST_DIR, RAG_TOP_K
)
from prompts import SYSTEM_PROMPT_RESP_ONLY
from rag import init_db, search_archive

from openai import OpenAI

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] [%(threadName)s] %(message)s',
    datefmt='%H:%M:%S',
    handlers=[logging.StreamHandler(sys.stdout)],
    force=True
)


# LED Ïï†ÎãàÎ©îÏù¥ÏÖò

async def run_scanning_led_bar(r, g, b, speed=0.08):
    """
    Î∞î LED(0~7)Í∞Ä Ï¢åÏö∞Î°ú ÏôïÎ≥µÌïòÎäî Ïä§Ï∫î Ïï†ÎãàÎ©îÏù¥ÏÖò (Knight Rider Ìö®Í≥º).
    """
    if not strip:
        return

    pos = 0
    direction = 1

    try:
        while True:
            for i in range(8):
                if i == pos:
                    # Î©îÏù∏ ÌîΩÏÖÄ (Î∞ùÏùå)
                    strip.set_pixel_color(i, Color(r, g, b))
                elif i == pos - direction and 0 <= i <= 7:
                    # Íº¨Î¶¨ ÏûîÏÉÅ (ÏïΩÌï®)
                    strip.set_pixel_color(i, Color(r // 5, g // 5, b // 5))
                else:
                    # ÎÇòÎ®∏ÏßÄ Í∫ºÏßê
                    strip.set_pixel_color(i, Color(0, 0, 0))
            
            strip.show()
            
            pos += direction
            if pos >= 7:
                direction = -1
            elif pos <= 0:
                direction = 1
                
            await asyncio.sleep(speed)
            
    except asyncio.CancelledError:
        raise

async def run_thinking_led_spin(r, g, b, speed=4.0, focus=10.0):
    """
    LLM ÏÉùÍ∞Å Ï§ë ÌëúÏãúÎ•º ÏúÑÌïú ÎπÑÎèôÍ∏∞ LED Ïï†ÎãàÎ©îÏù¥ÏÖò (ÏõêÌòï ÌöåÏ†Ñ).
    ThinkingStateÏóêÏÑú asyncio.create_taskÎ°ú Ïã§ÌñâÎê®.
    """
    if not strip:
        return
    
    ring_size = 8
    top_offset = 8
    bottom_offset = 16
    start_shift = 4 

    try:
        while True:
            t = time.time() * speed
            
            for i in range(ring_size):
                # Í∞ÅÎèÑ Î∞è ÌååÎèô Í≥ÑÏÇ∞
                angle = ((i - start_shift) / ring_size) * 2 * math.pi
                wave = math.sin(t + angle)
                
                # Î∞ùÍ∏∞ Í≥ÑÏÇ∞ (0 ~ 1)
                brightness = (wave + 1) / 2
                brightness = math.pow(brightness, focus)
                
                # ÏÉâÏÉÅ Ï†ÅÏö©
                cr = int(r * brightness)
                cg = int(g * brightness)
                cb = int(b * brightness)
                
                final_color = Color(cr, cg, cb)
                
                # ÏúÑ/ÏïÑÎûò ÎßÅ ÎèôÏãú Ï†ÅÏö©
                strip.set_pixel_color(top_offset + i, final_color)
                strip.set_pixel_color(bottom_offset + i, final_color)
            
            strip.show()
            await asyncio.sleep(0.02) # ÏïΩ 50 FPS
            
    except asyncio.CancelledError:
        raise

# ==================================================================================
# LLM tools
# =================================================================================
import re

# ÏùåÏïÖ Ïû¨ÏÉù
with open('assets/songs_db.json', 'r') as f:
    SONG_DB = json.load(f)

def normalize_string(input_str):
    return re.sub(r'\s+', '', input_str).lower()

song_candidates = []
for song in SONG_DB:
    song_processed = song.copy()
    song_processed['norm_title'] = normalize_string(song['title'])
    song_processed['norm_artist'] = normalize_string(song['artist'])
    song_candidates.append(song_processed)

def play_music(song_title: str = "", artist_name: str = ""):
    """
    LLMÏù¥ Ìò∏Ï∂úÌïòÎäî Ìï®Ïàò
    ÏÇ¨Ïö©ÏûêÍ∞Ä ÏöîÏ≤≠Ìïú Ï°∞Í±¥Ïóê ÎßûÎäî ÎÖ∏ÎûòÎ•º DBÏóêÏÑú Í≤ÄÏÉâÌïòÏó¨ Ïû¨ÏÉù
    """
    target_title = normalize_string(song_title)
    target_artist = normalize_string(artist_name)

    candidates = song_candidates

    if song_title:
        candidates = [s for s in candidates if target_title in s['norm_title']]

    if artist_name:
        candidates = [s for s in candidates if target_artist in s['norm_artist']]

    if candidates:
        selected_song = candidates[0]
        logging.info(f"Ïû¨ÏÉùÌï† ÎÖ∏Îûò Ï∞æÏùå: '{selected_song['title']}' by {selected_song['artist']}")
        return selected_song['file_path'], f"Found and playing '{selected_song['title']}' by {selected_song['artist']}."
    else:
        logging.info("Ïû¨ÏÉùÌï† ÎÖ∏ÎûòÎ•º Ï∞æÏßÄ Î™ªÌï®.")
        return None, "ÎÖ∏ÎûòÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§."


# ==================================================================================
# 0. Îß§ÎãàÏ†Ä ÌÅ¥ÎûòÏä§ (LLM/TTS Ïä§Î†àÎìú Í¥ÄÎ¶¨Ïö©)
# ==================================================================================
class LLMManager:
    def __init__(self, openai_api_key, conversation_manager, main_loop, websocket):
        self.client = OpenAI(api_key=openai_api_key)
        self.history_manager = conversation_manager
        self.main_loop = main_loop
        self.websocket = websocket
        
        # Í≤∞Í≥º Ï†ÑÎã¨Ïö© ÌÅê
        self.response_queue = queue.Queue()
        
        # Ïã§Ìñâ Ï†úÏñ¥Ïö©
        self._thread = None
        self._stop_event = threading.Event()
        self.current_request_id = 0

    def request_generation(self, user_text):
        """ThinkingStateÏóêÏÑú Ìò∏Ï∂ú: ÎãµÎ≥Ä ÏÉùÏÑ± ÏöîÏ≤≠"""
        self._stop_event.clear()
        self.current_request_id += 1
        request_id = self.current_request_id
        
        # Ïù¥Ï†Ñ ÌÅê ÎπÑÏö∞Í∏∞
        with self.response_queue.mutex:
            self.response_queue.queue.clear()
            
        # Î≥ÑÎèÑ Ïä§Î†àÎìúÏóêÏÑú Ïã§Ìñâ
        self._thread = threading.Thread(
            target=self._run_generation,
            args=(user_text, request_id),
            name=f"LLMThread-{request_id}",
            daemon=True
        )
        self._thread.start()

    def cancel(self):
        """Ïù∏ÌÑ∞ÎüΩÏÖò Î∞úÏÉù Ïãú Ìò∏Ï∂ú: ÏûëÏóÖ Ï∑®ÏÜå"""
        self._stop_event.set()
        self.current_request_id += 1 # ÌòÑÏû¨ ÏûëÏóÖ ID Î¨¥Ìö®Ìôî

    def _run_generation(self, user_text, request_id):
        try:
            llm_start_time = time.time()

            # ID Í≤ÄÏ¶ù
            if self.current_request_id != request_id: return

            # 1. ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄ Í∏∞Î°ù
            self.history_manager.add_message({"role": "user", "content": user_text, "type": "message"})
            current_log = self.history_manager.get_current_log()
            
            # 2. ÎèÑÍµ¨ Ï†ïÏùò
            tools = [
                {
                    "type": "web_search",
                    "user_location": {"type": "approximate", "country": "KR"},
                },
                {
                    "type": "function",
                    "name": "play_music",
                    "description": "ÏÇ¨Ïö©ÏûêÍ∞Ä ÏöîÏ≤≠Ìïú ÎÖ∏ÎûòÎ•º Í≤ÄÏÉâÌïòÏó¨ Ïû¨ÏÉùÌï©ÎãàÎã§. Ï†ÄÏû•Îêú DBÏóê ÏûàÎäî ÎÖ∏ÎûòÎßå Ïû¨ÏÉù Í∞ÄÎä•Ìï©ÎãàÎã§.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "song_title": {"type": "string"},
                            "artist_name": {"type": "string"},
                        },
                        "required": ["song_title", "artist_name"] 
                    }
                },
                {
                    "type": "function",
                    "name": "consult_archive",
                    "description": "ÏòÅÌôî/ÏùåÏïÖÏóê ÎåÄÌïú Ï†ïÎ≥¥Î•º Ï∞æÍ±∞ÎÇò, ÏÇ¨Ïö©ÏûêÏùò Í∏∞Î∂Ñ/ÏÉÅÌô©Ïóê ÎßûÎäî ÏûëÌíàÏùÑ Ïó∞ÏÉÅÌï† Îïå ÏÇ¨Ïö©Ìï©ÎãàÎã§. ÏÇ¨Ïã§ ÌôïÏù∏, ÏúÑÎ°ú, Í≥µÍ∞ê, Ï∂îÏ≤úÏù¥ ÌïÑÏöîÌï† Îïå Ï†ÅÍ∑πÏ†ÅÏúºÎ°ú ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "Í≤ÄÏÉâÌï† ÌÇ§ÏõåÎìú ÎòêÎäî Î¨∏Ïû• (Ïòà: 'ÎπÑ Ïò§Îäî ÎÇ†Ïùò Ïö∞Ïö∏Ìï®', 'Ìó§Ïñ¥Ïßà Í≤∞Ïã¨ Ìï¥ÏÑù')"
                            },
                            "intent": {
                                "type": "string",
                                "enum": ["fact", "vibe", "critique"],
                                "description": "fact=ÏÇ¨Ïã§Ï†ïÎ≥¥(Í∞êÎèÖ/Ï∂úÏó∞ÏßÑ), vibe=Î∂ÑÏúÑÍ∏∞/Ï∂îÏ≤ú, critique=ÌèâÎ°†/Ìï¥ÏÑù"
                            }
                        },
                        "required": ["query", "intent"]
                    }
                }
            ]

            # 3. Responses API Ìò∏Ï∂ú (1Ï∞®)
            if self._stop_event.is_set() or self.current_request_id != request_id: return

            params = {
                **RESPONSES_PRESETS.get(RESPONSES_MODEL, {}),
                "input": current_log,
                "tools": tools,
            }
            response = self.client.responses.create(**params)
            
            final_text = ""
            music_action = None
            motion_thread = None

            # 4. Responses Í≤∞Í≥º Ï≤òÎ¶¨ Î£®ÌîÑ
            for item in response.output:
                if self._stop_event.is_set() or self.current_request_id != request_id: return

                if item.type == "message":
                    final_text = item.content[0].text.strip()
                    break

                elif item.type == "function_call":
                    logging.info(f"üß† Function call: {item.name}")
                    
                    if item.name == "play_music":
                        self.history_manager.add_message(item)
                        args = json.loads(item.arguments)
                        song_title = args.get("song_title", "")
                        artist_name = args.get("artist_name", "")

                        # (1) ÎÖ∏Îûò Ï∞æÍ∏∞
                        file_path, message = play_music(song_title, artist_name)
                        status = "failure"

                        if file_path:
                            status = "success"
                            audio_name = f"{song_title}_{artist_name}"
                            csv_path = os.path.join(ASSETS_DIR, "headMotion", f"{audio_name}.csv")

                            # (2) Î™®ÏÖò ÏÉùÏÑ± (ÏóÜÏùÑ Í≤ΩÏö∞) - Ïä§Î†àÎìúÎ°ú Î∂ÑÎ¶¨ÌïòÏó¨ Î≥ëÎ†¨ Ï≤òÎ¶¨
                            if not os.path.exists(os.path.join(ASSETS_DIR, "headMotion", f"{audio_name}.csv")):
                                if not os.path.exists(csv_path):
                                    logging.info(f"‚öôÔ∏è Î™®ÏÖò ÌååÏùº ÏóÜÏùå. ÏÉùÏÑ± ÏãúÏûë: {audio_name}")
                                    motion_thread = threading.Thread(
                                        target=offline_motion_generation,
                                        args=(audio_name,),
                                        name=f"MotionGenThread-{audio_name}"
                                    )
                                    motion_thread.start()
                            
                            # Ïï°ÏÖò Ï†ïÎ≥¥ Ï†ÄÏû•
                            music_action = {"audio_name": audio_name, "motion_thread": motion_thread}
                        
                        # (3) Ìï®Ïàò Ìò∏Ï∂ú Í≤∞Í≥º Í∏∞Î°ù
                        function_call_output = {
                            "type": "function_call_output",
                            "call_id": item.call_id,
                            "output": json.dumps({"status": status, "message": message})
                        }
                        self.history_manager.add_message(function_call_output)

                        # (4) 2Ï∞® Responses API Ìò∏Ï∂ú (Í≤∞Í≥º Î©òÌä∏ ÏÉùÏÑ±)
                        response_2 = self.client.responses.create(**params)

                        if response_2.output:
                            for item in response_2.output:
                                if item.type == "message" and item.content:
                                    final_text = item.content[0].text.strip()
                                    break
                        break
                    
                    elif item.name == "consult_archive":
                        # RAG Í≤ÄÏÉâ - ÌúòÎ∞úÏÑ± Í∏∞Ïñµ Ìå®ÌÑ¥ (temp_log ÏÇ¨Ïö©)
                        args = json.loads(item.arguments)
                        query = args.get("query", "")
                        intent = args.get("intent", "vibe")
                        
                        logging.info(f"üìö RAG Í≤ÄÏÉâ: query='{query}', intent='{intent}'")
                        
                        # Í≤ÄÏÉâ ÏàòÌñâ
                        search_result = search_archive(query, intent, top_k=RAG_TOP_K)
                        
                        # ÏûÑÏãú Î°úÍ∑∏ ÏÉùÏÑ± (ÌúòÎ∞úÏÑ± - Ï†ÄÏû•ÌïòÏßÄ ÏïäÏùå)
                        temp_log = current_log.copy()
                        temp_log.append({
                            "type": "function_call",
                            "name": item.name,
                            "call_id": item.call_id,
                            "arguments": item.arguments
                        })
                        temp_log.append({
                            "type": "function_call_output",
                            "call_id": item.call_id,
                            "output": search_result
                        })
                        
                        # 2Ï∞® Responses API Ìò∏Ï∂ú (Í≤ÄÏÉâ Í≤∞Í≥º Í∏∞Î∞ò ÎãµÎ≥Ä ÏÉùÏÑ±)
                        params_with_context = {
                            **RESPONSES_PRESETS.get(RESPONSES_MODEL, {}),
                            "input": temp_log,
                            "tools": tools,
                        }
                        response_2 = self.client.responses.create(**params_with_context)
                        
                        if response_2.output:
                            for resp_item in response_2.output:
                                if resp_item.type == "message" and resp_item.content:
                                    final_text = resp_item.content[0].text.strip()
                                    break
                        break

            # 5. Í≤∞Í≥º Î∞òÌôò
            if self._stop_event.is_set() or self.current_request_id != request_id: return

            if final_text:
                self.history_manager.add_message({"role": "assistant", "content": final_text, "type": "message"})

            logging.info(f"üß† ÎãµÎ≥Ä ÏÉùÏÑ± ÏôÑÎ£å: {final_text} (ÏÜåÏöî ÏãúÍ∞Ñ: {time.time() - llm_start_time:.2f}Ï¥à)")

            result_package = {"text": final_text, "action": music_action}

            if self.current_request_id == request_id:
                self.response_queue.put(result_package)

        except Exception as e:
            logging.error(f"‚ùå LLM Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {e}")
            if self.current_request_id == request_id:
                self.response_queue.put(None)

    def request_hesitation(self):
        """HesitatingStateÏóêÏÑú Ìò∏Ï∂ú: Î≥µÍµ¨ Î©òÌä∏ ÏÉùÏÑ± ÏöîÏ≤≠"""
        self._stop_event.clear()
        self.current_request_id += 1
        request_id = self.current_request_id
        
        # ÌÅê ÎπÑÏö∞Í∏∞
        with self.response_queue.mutex:
            self.response_queue.queue.clear()
            
        self._thread = threading.Thread(
            target=self._run_hesitation,
            args=(request_id,),
            name=f"HesitationLLMThread-{request_id}",
            daemon=True
        )
        self._thread.start()

    def _run_hesitation(self, request_id):
        try:
            if self.current_request_id != request_id: return

            # 1. ÌòÑÏû¨ Î°úÍ∑∏ Í∞ÄÏ†∏Ïò§Í∏∞ (ÏõêÎ≥∏)
            current_log = self.history_manager.get_current_log()
            
            # 2. ÏûÑÏãú Î°úÍ∑∏ ÏÉùÏÑ± (Î≥µÏÇ¨Î≥∏Ïóê ÏãúÏä§ÌÖú Î©îÏãúÏßÄ Ï∂îÍ∞Ä)
            # Ï£ºÏùò: Î¶¨Ïä§Ìä∏Î•º ÏñïÏùÄ Î≥µÏÇ¨(copy())Ìï¥ÏÑú ÏõêÎ≥∏ historyÏóêÎäî ÏòÅÌñ• ÏóÜÍ≤å Ìï®
            temp_log = current_log.copy()
            
            # ÏÉÅÌô© ÏÑ§Î™Ö ÏãúÏä§ÌÖú Î©îÏãúÏßÄ Ï£ºÏûÖ
            system_instruction = {
                "role": "system",
                "content": (
                    "ÏÉÅÌô©: ÏÇ¨Ïö©ÏûêÍ∞Ä Î°úÎ¥áÏùò ÎßêÏùÑ ÎÅäÍ≥† Î¨¥Ïñ∏Í∞Ä ÎßêÌïòÎ†§ ÌñàÏúºÎÇò, Î°úÎ¥áÏù¥ Ï†úÎåÄÎ°ú ÏïåÏïÑÎì£ÏßÄ Î™ªÌñàÏäµÎãàÎã§(STT Ïã§Ìå®/Ïπ®Î¨µ). Ïù¥ÌõÑ ÏïΩ 3Ï¥àÍ∞Ñ ÏÇ¨Ïö©ÏûêÏùò Ï∂îÍ∞Ä Î∞úÌôîÍ∞Ä ÏóÜÏäµÎãàÎã§."
                    "ÏßÄÏπ®: ÏÉÅÌô©Ïóê ÎßûÍ≤å, ÏÇ¨Ïö©ÏûêÍ∞Ä Îã§Ïãú ÎßêÌïòÎèÑÎ°ù ÏûêÏó∞Ïä§ÎüΩÍ≤å Ïú†ÎèÑÌïòÎäî ÏßßÏùÄ Î¨∏Ïû•ÏùÑ ÏÉùÏÑ±ÌïòÍ±∞ÎÇò Ïπ®Î¨µ ÏÉÅÌÉúÎ•º Ïù∏ÏßÄÌïòÍ≥† Ï†ÅÏ†àÌûà ÎåÄÏùëÌïòÎäî Î¨∏Ïû•ÏùÑ ÏÉùÏÑ±ÌïòÏÑ∏Ïöî."
                    "ÏòàÏãú: 'Ï£ÑÏÜ°Ìï¥Ïöî, Î∞©Í∏à ÎßêÏîÄÏùÑ ÎÜìÏ≥§Ïñ¥Ïöî.', 'ÌòπÏãú Î¨¥Ïñ∏Í∞Ä ÎßêÏîÄÏùÑ ÌïòÏÖ®ÎÇòÏöî?' 'Ïù¥Ïñ¥ÏÑú ÎßêÌï¥ÎèÑ Îê†ÍπåÏöî?' "
                    "Ï£ºÏùò: ÎÑàÎ¨¥ Í∏∏ÏßÄ ÏïäÍ≤å, Í∞ÑÍ≤∞ÌïòÍ≥† ÏûêÏó∞Ïä§ÎüΩÍ≤å ÏÉÅÌô©Ïóê ÎßûÍ≤å ÎãµÎ≥ÄÌïòÏÑ∏Ïöî."
                )
            }
            temp_log.append(system_instruction)

            # 3. Responses API Ìò∏Ï∂ú
            if self._stop_event.is_set() or self.current_request_id != request_id: return

            params = {
                **RESPONSES_PRESETS.get(RESPONSES_MODEL, {}),
                "model": RESPONSES_MODEL,
                "input": temp_log,
                # HesitationÏóêÏÑúÎäî ÎèÑÍµ¨(Tools) ÏÇ¨Ïö© Ïïà Ìï® (Îã®Ïàú Î∞úÌôîÎßå)
            }

            response = self.client.responses.create(**params)
            
            final_text = ""
            if response.output:
                for item in response.output:
                    if item.type == "message" and item.content:
                        final_text = item.content[0].text.strip()
                        break

            # 4. Í≤∞Í≥º Ï≤òÎ¶¨
            if not self._stop_event.is_set() and final_text and self.current_request_id == request_id:
                logging.info(f"ü§î Î≥µÍµ¨ Î©òÌä∏ ÏÉùÏÑ±: {final_text}")
                
                # Ïó¨Í∏∞ÏÑúÎäî HistoryÏóê Ï∂îÍ∞ÄÌïòÏßÄ ÏïäÏùå.
                # ÎÇòÏ§ëÏóê SpeakingStateÎ°ú ÎÑòÏñ¥Í∞à Îïå(ÌôïÏ†ïÎê† Îïå) Ï∂îÍ∞Ä
                
                # Í≤∞Í≥º Ìå®ÌÇ§ÏßÄ (Action ÏóÜÏùå)
                result_package = {
                    "text": final_text,
                    "action": None,
                    "is_hesitation": True # ÌîåÎûòÍ∑∏ Ï∂îÍ∞Ä
                }
                self.response_queue.put(result_package)

        except Exception as e:
            logging.error(f"‚ùå Hesitation LLM Ïò§Î•ò: {e}")
            if self.current_request_id == request_id:
                self.response_queue.put(None)


class TTSManager:
    def __init__(self, openai_api_key, main_loop, websocket):
        self.client = OpenAI(api_key=openai_api_key)
        self.main_loop = main_loop
        self.websocket = websocket
        
        self.is_playing = False
        self.playback_started_event = threading.Event()
        self._stop_event = threading.Event()
        self._thread = None

    def speak(self, text):
        """TTS Ïä§Ìä∏Î¶¨Î∞ç ÏãúÏûë (ThinkingState Ìò∏Ï∂ú)"""
        self._stop_event.clear()
        self.playback_started_event.clear()
        self.is_playing = True
        
        self._thread = threading.Thread(
            target=self._run_tts,
            args=(text,),
            name="TTS_Thread",
            daemon=True
        )
        self._thread.start()

    def stop(self):
        """TTS Ï¶âÏãú Ï§ëÎã® (SpeakingState Ïù∏ÌÑ∞ÎüΩÏÖò Ìò∏Ï∂ú)"""
        if self.is_playing:
            logging.info("üîá TTS Ï§ëÎã® ÏöîÏ≤≠")
            self._stop_event.set() # 1. Î£®ÌîÑ ÌîåÎûòÍ∑∏ ÏÑ§Ï†ï
            self.is_playing = False
            
            # 2. C++ Ïò§ÎîîÏò§ Î≤ÑÌçº ÌÅ¥Î¶¨Ïñ¥ Î™ÖÎ†π (ÏÑ†ÌÉù ÏÇ¨Ìï≠)
            # asyncio.run_coroutine_threadsafe(
            #     self.websocket.send(json.dumps({"type": "stop_audio"})),
            #     self.main_loop
            # )

    def _run_tts(self, text):
        try:
            # 1. Ïä§Ìä∏Î¶¨Î∞ç ÏãúÏûë ÏïåÎ¶º (C++ Î™®ÏÖò Ï§ÄÎπÑ Îì±)
            tts_start_time = time.time()
            if self.websocket:
                asyncio.run_coroutine_threadsafe(
                    self.websocket.send(json.dumps({"type": "responses_only"})),
                    self.main_loop
                )

            # 2. OpenAI TTS Ìò∏Ï∂ú (Stream)
            with self.client.audio.speech.with_streaming_response.create(
                model=TTS_MODEL, voice=VOICE, input=text, response_format="pcm"
            ) as response:
                first_chunk = True

                # 3. Ï≤≠ÌÅ¨ Ï†ÑÏÜ° Î£®ÌîÑ
                for chunk in response.iter_bytes(chunk_size=4096):
                    # Ï§ëÎã® ÏöîÏ≤≠ Ï≤¥ÌÅ¨
                    if self._stop_event.is_set():
                        logging.info("üõë TTS Ïä§Ìä∏Î¶¨Î∞ç Î£®ÌîÑ ÌÉàÏ∂ú")
                        break
                    
                    # ÏõπÏÜåÏºì Ï†ÑÏÜ°
                    if self.websocket:
                        asyncio.run_coroutine_threadsafe(
                            self.websocket.send(json.dumps({
                                "type": "responses_audio_chunk",
                                "data": base64.b64encode(chunk).decode('utf-8')
                            })),
                            self.main_loop
                        )

                    # Ï≤´ Ï≤≠ÌÅ¨ Ï†ÑÏÜ° ÏãúÏ†êÏóê 'Ïû¨ÏÉù ÏãúÏûë' Í∞ÑÏ£º
                    if first_chunk:
                        logging.info("üîä TTS Ï≤´ Ï≤≠ÌÅ¨ Ï†ÑÏÜ° -> Playback Started")
                        self.playback_started_event.set()
                        first_chunk = False

            # 4. Ïä§Ìä∏Î¶¨Î∞ç ÏôÑÎ£å Ï≤òÎ¶¨
            if not self._stop_event.is_set():
                if self.websocket:
                    asyncio.run_coroutine_threadsafe(
                        self.websocket.send(json.dumps({"type": "responses_stream_end"})),
                        self.main_loop
                    )

            logging.info(f"TTS Ïä§Ìä∏Î¶¨Î∞ç ÏôÑÎ£å (ÏÜåÏöîÏãúÍ∞Ñ: {time.time() - tts_start_time:.2f}Ï¥à)")

        except Exception as e:
            logging.error(f"‚ùå TTS Ïä§Ìä∏Î¶¨Î∞ç Ïò§Î•ò: {e}", exc_info=True)
        finally:
            self.is_playing = False
            # ÌòπÏãú ÏóêÎü¨ÎÇòÏÑú ÏãúÏûë Ïù¥Î≤§Ìä∏Í∞Ä Ïïà ÏºúÏ°åÏúºÎ©¥, Î¨¥Ìïú ÎåÄÍ∏∞ Î∞©ÏßÄÎ•º ÏúÑÌï¥ ÏºúÏ§å
            if not self.playback_started_event.is_set():
                self.playback_started_event.set()

# ==================================================================================
# 1. State Interface
# ==================================================================================
class ConversationState(ABC):
    def __init__(self, engine):
        self.engine = engine

    @abstractmethod
    def on_enter(self):
        """ÏÉÅÌÉú ÏßÑÏûÖ Ïãú 1Ìöå Ïã§Ìñâ"""
        pass

    @abstractmethod
    def update(self, chunk: np.ndarray) -> 'ConversationState | None':
        """
        Î©îÏù∏ Î£®ÌîÑÏóêÏÑú Ï£ºÍ∏∞Ï†ÅÏúºÎ°ú Ìò∏Ï∂úÎê®.
        - chunk: ÎßàÏù¥ÌÅ¨ ÏûÖÎ†• (VAD Î∂ÑÏÑùÏö©)
        - return: ÏÉÅÌÉú Ï†ÑÏù¥Í∞Ä ÌïÑÏöîÌïòÎ©¥ State Í∞ùÏ≤¥ Î∞òÌôò, ÏïÑÎãàÎ©¥ None
        """
        pass

    @abstractmethod
    def on_exit(self):
        """ÏÉÅÌÉú ÌÉàÏ∂ú Ïãú 1Ìöå Ïã§Ìñâ"""
        pass

# ==================================================================================
# 2. State Implementations
# ==================================================================================

class SleepState(ConversationState):
    """
    ÏãúÏûë ÌÇ§ÏõåÎìúÎßå Í∏∞Îã§Î¶¨Îäî ÎåÄÍ∏∞ ÏÉÅÌÉú.
    """
    def on_enter(self):
        logging.info("--- STATE: [Sleep] ÏãúÏûë ÌÇ§ÏõåÎìú ÎåÄÍ∏∞ Ï§ë... ---")
        # LED Off or Dimmed
        # Ring: Warm White, Bar: Off
        led_set_dual(bar_color=(0, 0, 0), ring_color=(100, 100, 30))
        self.engine.vad_processor.reset()
        
        # ÌÅê ÎπÑÏö∞Í∏∞
        with self.engine.stt_audio_queue.mutex:
            self.engine.stt_audio_queue.queue.clear()

    def update(self, chunk):
        if chunk is None: return None

        # 1. Î≤ÑÌçºÎßÅ (ÌÇ§ÏõåÎìú ÏïûÎ∂ÄÎ∂Ñ ÏûòÎ¶º Î∞©ÏßÄ)
        self.engine.stt_pre_buffer.append(chunk)

        # 2. VAD Í∞êÏßÄ
        if self.engine.vad_processor.process(chunk):
            logging.info("üí§ Sleep Ï§ë Î∞úÌôî Í∞êÏßÄ -> ÌÇ§ÏõåÎìú ÌôïÏù∏(Listening) Î™®Îìú ÏßÑÏûÖ")
            
            return ListeningState(self.engine, mode="WAKEWORD")
            
        return None

    def on_exit(self):
        pass


class IdleState(ConversationState):
    def on_enter(self):
        logging.info("--- STATE: [Idle] Î∞úÌôî ÎåÄÍ∏∞ Ï§ë... ---")
        led_set_dual((233, 233, 50), (233, 233, 50))

        # VAD ÏÉÅÌÉú Î¶¨ÏÖã (Ïù¥Ï†Ñ Ïû°Ïùå ÏòÅÌñ• Ï†úÍ±∞)
        self.engine.vad_processor.reset()
        self.last_activity_time = time.time()

    def update(self, chunk):
        if chunk is not None:
            self.engine.stt_pre_buffer.append(chunk)

            # Î∞úÌôî Í∞êÏßÄ
            if self.engine.vad_processor.process(chunk):
                logging.info("üó£Ô∏è Î∞úÌôî ÏãúÏûë Í∞êÏßÄ")
                return ListeningState(self.engine, is_interruption=False, mode="NORMAL")
    
        # ÌÉÄÏûÑÏïÑÏõÉ Í∞êÏßÄ
        if time.time() - self.last_activity_time > self.engine.active_timeout:
            logging.info(f"‚è∞ {self.engine.active_timeout}Ï¥àÍ∞Ñ ÏûÖÎ†• ÏóÜÏùå -> Sleep Ï†ÑÌôò")

            # Ï¢ÖÎ£å ÏÇ¨Ïö¥Îìú Ïû¨ÏÉù
            if self.engine.websocket:
                asyncio.run_coroutine_threadsafe(
                    self.engine.websocket.send(json.dumps({"type": "play_audio", "file_to_play": str(SLEEP_FILE)})),
                    self.engine.main_loop
                )
            
            # Î≥ÑÎèÑ Ïä§Î†àÎìúÏóêÏÑú ÏÑ∏ÏÖò Ï¥àÍ∏∞Ìôî Î∞è ÏöîÏïΩ ÏûëÏóÖ ÏàòÌñâ
            self.engine.history_manager.end_session()

            # Sleep ÏÉÅÌÉúÎ°ú Ï†ÑÌôò
            return SleepState(self.engine)
        
        return None

    def on_exit(self):
        pass


class ListeningState(ConversationState):
    def __init__(self, engine, is_interruption=False, mode="NORMAL"):
        super().__init__(engine)
        self.is_interruption = is_interruption
        self.mode = mode # NORMAL | WAKEWORD

        # ÌòÑÏû¨ ÌÑ¥ Ïò§ÎîîÏò§ Î≤ÑÌçº (SmartTurnÏö©)
        self.audio_buffer = []

        # ÌÑ¥ Í∞êÏßÄ Í¥ÄÎ†® Î≥ÄÏàò
        self.silent_chunks = 0
        self.turn_mode = "LISTENING" # LISTENING | GRACE
        self.grace_period_end_time = None

        # STT Ïä§Î†àÎìú Ìï∏Îì§
        self.stt_thread = None

    def on_enter(self):
        logging.info(f"--- STATE: [Listening] ÏÇ¨Ïö©Ïûê ÏûÖÎ†• Î∞õÎäî Ï§ë... (Interruption={self.is_interruption}) ---")

        # LED
        if self.mode == "NORMAL":
            # Bar: Red, Ring: Yellow (Explicit refresh)
            led_set_dual((233, 50, 50), (233, 233, 50))

        # 1. ÌÅê Ï¥àÍ∏∞Ìôî (Ïù¥Ï†Ñ ÌÑ¥Ïùò ÏûîÏó¨ Îç∞Ïù¥ÌÑ∞ Ï†úÍ±∞)
        with self.engine.stt_audio_queue.mutex:
            self.engine.stt_audio_queue.queue.clear()
        
        with self.engine.stt_result_queue.mutex:
            self.engine.stt_result_queue.queue.clear()

        # 2. STT ÏãúÏûë
        self.engine.stt_stop_event.clear()
        self.stt_thread = threading.Thread(
            target=self.engine.stt_streamer.run_stt_session,
            name="STTSessionThread",
            daemon=True
        )
        self.stt_thread.start()

        # 3. Pre-buffer Ï≤òÎ¶¨
        # EngineÏóê ÏûàÎäî Î≤ÑÌçºÎ•º ÌÑ∏Ïñ¥ÏÑú STT ÌÅêÏôÄ ÎÇ¥ Î≤ÑÌçºÏóê ÎÑ£Ïùå
        if self.engine.stt_pre_buffer:
            for chunk in self.engine.stt_pre_buffer:
                self.engine.stt_audio_queue.put(chunk)
                self.audio_buffer.append(chunk)
            self.engine.stt_pre_buffer.clear() # Ï≤òÎ¶¨ ÌñàÏúºÎãà ÎπÑÏõÄ
        
        # 4. Ïù∏ÌÑ∞ÎüΩÏÖò Ï≤òÎ¶¨
        if self.is_interruption and self.engine.websocket:
            # C++Î°ú Ïù∏ÌÑ∞ÎüΩÏÖò Ïã†Ìò∏ Ï†ÑÏÜ°
            asyncio.run_coroutine_threadsafe(
                self.engine.websocket.send(json.dumps({"type": "user_interruption"})),
                self.engine.main_loop
            )

    def update(self, chunk):
        if chunk is None: return None

        # 1. Ïò§ÎîîÏò§ Îç∞Ïù¥ÌÑ∞ Í≥µÍ∏â
        self.engine.stt_audio_queue.put(chunk)
        self.audio_buffer.append(chunk)

        # 2. VAD Î∂ÑÏÑù
        is_speech = self.engine.vad_processor.process(chunk)

        if is_speech:
            self.silent_chunks = 0
            if self.turn_mode == "GRACE":
                logging.info("üîÑ Ïú†Ïòà ÏãúÍ∞Ñ Ï§ë Ïû¨Î∞úÌôî -> Í≥ÑÏÜç Îì£Í∏∞")
                self.turn_mode = "LISTENING"
                self.grace_period_end_time = None
        else:
            self.silent_chunks += 1

        # 3. ÌÑ¥ Ï¢ÖÎ£å ÌåêÎã®
        # [Case A] Ïú†Ïòà ÏãúÍ∞Ñ Î™®Îìú
        if self.turn_mode == "GRACE":
            if time.time() >= self.grace_period_end_time:
                logging.info("‚è≥ Ïú†Ïòà ÏãúÍ∞Ñ Ï¢ÖÎ£å -> ÌÑ¥ Ï¢ÖÎ£å ÌôïÏ†ï")
                return self._finish_listening()
            return None
        
        # [Case B] ÏùºÎ∞ò Îì£Í∏∞ Î™®Îìú (VAD Ïπ®Î¨µ ÏßÄÏÜç Ïãú)
        if self.silent_chunks > TURN_END_SILENCE_CHUNKS:
            prediction = self._run_smart_turn()
            
            if prediction == 1: # [Ï¢ÖÎ£å]
                logging.info("ü§ñ SmartTurn: Ï¢ÖÎ£å(1) ÏòàÏ∏°")
                return self._finish_listening()
            
            elif prediction == 0: # [ÏßÑÌñâÏ§ë]
                logging.info(f"ü§ñ SmartTurn: ÏßÑÌñâÏ§ë(0) ÏòàÏ∏° -> Ïú†Ïòà ÏßÑÏûÖ ({SMART_TURN_GRACE_PERIOD}s)")
                self.turn_mode = "GRACE"
                self.grace_period_end_time = time.time() + SMART_TURN_GRACE_PERIOD
                self.silent_chunks = 0 # Ï§ëÎ≥µ Ï≤¥ÌÅ¨ Î∞©ÏßÄ

        return None

    def _run_smart_turn(self):
        # StateÍ∞Ä Í¥ÄÎ¶¨ÌïòÎäî audio_buffer ÏÇ¨Ïö©
        if not self.audio_buffer: return 0
        
        concatenated = np.concatenate([c.flatten() for c in self.audio_buffer])
        full_audio = concatenated.astype(np.float32) / 32768.0
        
        result = self.engine.smart_turn_processor.predict(full_audio)
        return result['prediction']
    
    def _finish_listening(self):
        """Îì£Í∏∞ Ï¢ÖÎ£å ÌõÑ Îã§Ïùå ÏÉÅÌÉú Í≤∞Ï†ï"""
        return SttResultWaitingState(
            self.engine, 
            was_interruption=self.is_interruption,
            mode=self.mode
        )

    def on_exit(self):
        logging.info("üõë Listening Ï¢ÖÎ£å -> STT Ï§ëÎã® Ïã†Ìò∏")
        self.engine.stt_stop_event.set()
        self.engine.stt_audio_queue.put(None)


class SttResultWaitingState(ConversationState):
    """STT ÏÑúÎ≤ÑÎ°úÎ∂ÄÌÑ∞ ÏµúÏ¢Ö Í≤∞Í≥ºÎ•º Í∏∞Îã§Î¶¨Îäî ÏÉÅÌÉú"""
    def __init__(self, engine, was_interruption, mode="NORMAL"):
        super().__init__(engine)
        self.was_interruption = was_interruption
        self.mode = mode # NORMAL | WAKEWORD

        self.start_time = 0.0

    def on_enter(self):
        logging.info("--- STATE: [SttResultWaiting] STT Í≤∞Í≥º ÎåÄÍ∏∞Ï§ë... ---")
        self.start_time = time.time()
        if self.mode == "NORMAL":
            # Bar: Yellow, Ring: Yellow
            led_set_dual((233, 233, 50), (233, 233, 50))

    def update(self, chunk):
        # Ïò§ÎîîÏò§ Ï≤≠ÌÅ¨Îäî Î¨¥Ïãú
        
        # 1. STT Í≤∞Í≥º ÌÅê ÌôïÏù∏ (Non-blocking)
        try:
            text = self.engine.stt_result_queue.get_nowait()
            
            if text is None:
                # STT Ïã§Ìå® Ïã†Ìò∏ ÏàòÏã† -> Ï¶âÏãú Ïã§Ìå® Ï≤òÎ¶¨
                logging.info("STT Ïù∏Ïãù Ïã§Ìå®(None) ÏàòÏã†")
                return self._handle_failure()
            
            logging.info(f"üìù STT Í≤∞Í≥º: '{text}' (Mode={self.mode})")

            if self.mode == "WAKEWORD":
                if self.engine.start_keyword in text:
                    logging.info(f"‚ú® ÏãúÏûë ÌÇ§ÏõåÎìú Í∞êÏßÄ! -> Active Î™®Îìú ÏãúÏûë")
                
                    # 1. Íπ®Ïñ¥ÎÇ® ÏÇ¨Ïö¥Îìú Ïû¨ÏÉù
                    if self.engine.websocket:
                        asyncio.run_coroutine_threadsafe(
                            self.engine.websocket.send(json.dumps({"type": "play_audio", "file_to_play": str(AWAKE_FILE)})),
                            self.engine.main_loop
                        )
                    
                    # 2. ÏÉà ÏÑ∏ÏÖò ÏÉùÏÑ±
                    self.engine.history_manager.start_new_session(system_prompt=SYSTEM_PROMPT_RESP_ONLY)

                    return IdleState(self.engine)
                else:
                    logging.info("ÌÇ§ÏõåÎìú Î∂àÏùºÏπò -> Îã§Ïãú Sleep")
                    return SleepState(self.engine)
            
            else:
                # Ï¢ÖÎ£å ÌÇ§ÏõåÎìú Í≤ÄÏÇ¨
                if any(kw in text for kw in self.engine.end_keywords):
                    logging.info(f"üëã Ï¢ÖÎ£å ÌÇ§ÏõåÎìú Í∞êÏßÄ: '{text}' -> Sleep Ï†ÑÌôò")

                    # Ï¢ÖÎ£å ÏÇ¨Ïö¥Îìú Ïû¨ÏÉù
                    if self.engine.websocket:
                        asyncio.run_coroutine_threadsafe(
                            self.engine.websocket.send(json.dumps({"type": "play_audio", "file_to_play": str(SLEEP_FILE)})),
                            self.engine.main_loop
                        )
                    self.engine.history_manager.end_session()
                    return SleepState(self.engine)
                
            # ÏùºÎ∞ò ÎåÄÌôî --> ThinkingStateÎ°ú ÏßÑÌñâ
            return ThinkingState(self.engine, text)
            
        except queue.Empty:
            # ÏïÑÏßÅ Í≤∞Í≥ºÍ∞Ä ÎèÑÏ∞©ÌïòÏßÄ ÏïäÏùå -> ÌÉÄÏûÑÏïÑÏõÉ Ï≤¥ÌÅ¨
            pass

        # 2. ÌÉÄÏûÑÏïÑÏõÉ Ï≤òÎ¶¨
        # ÎÑ§Ìä∏ÏõåÌÅ¨ ÏßÄÏó∞ Îì±ÏúºÎ°ú STT Í≤∞Í≥ºÍ∞Ä ÏòÅÏõêÌûà Ïïà Ïò¨ Í≤ΩÏö∞Î•º ÎåÄÎπÑ
        if time.time() - self.start_time > STT_WAIT_TIMEOUT_SECONDS:
            logging.warning(f"‚ö†Ô∏è STT Í≤∞Í≥º ÎåÄÍ∏∞ ÏãúÍ∞Ñ Ï¥àÍ≥º ({STT_WAIT_TIMEOUT_SECONDS}s)")
            return self._handle_failure()
                    
        return None # Í≥ÑÏÜç ÎåÄÍ∏∞

    def _handle_failure(self):
        """Í≤∞Í≥º ÏàòÏã† Ïã§Ìå®(Îπà Í∞í, ÌÉÄÏûÑÏïÑÏõÉ) Ïãú Î∂ÑÍ∏∞ Ï≤òÎ¶¨"""
        if self.mode == "WAKEWORD":
            logging.info("Îã®Ïàú ÏÜåÏùå ÎòêÎäî Ïù∏Ïãù Ïã§Ìå® -> Sleep Î≥µÍ∑Ä")
            return SleepState(self.engine) 
        if self.was_interruption:
            # Ïù∏ÌÑ∞ÎüΩÏÖòÏù¥ÏóàÎäîÎç∞ Ïã§Ìå®Ìï® -> "Î≠êÎùºÍ≥† ÌïòÏÖ®Ï£†?" Î≥µÍµ¨ ÏãúÎèÑ
            logging.info("Ïù∏ÌÑ∞ÎüΩÏÖò Ïù∏Ïãù Ïã§Ìå® -> Hesitating(Î≥µÍµ¨) Î™®Îìú ÏßÑÏûÖ")
            return HesitatingState(self.engine)
        else:
            # Í∑∏ÎÉ• ÌòºÏûê ÎßêÌïòÎã§ Î©àÏ∂ò Í≤É -> Î¨¥ÏãúÌïòÍ≥† ÎåÄÍ∏∞
            logging.info("Îã®Ïàú ÏÜåÏùå ÎòêÎäî Ïù∏Ïãù Ïã§Ìå® -> Idle Î≥µÍ∑Ä")
            return IdleState(self.engine)

    def on_exit(self):
        pass


class HesitatingState(ConversationState):
    """
    Ïù∏ÌÑ∞ÎüΩÏÖòÏù∏ Ï§Ñ ÏïåÏïòÎäîÎç∞ STTÍ∞Ä ÎπÑÏóàÏùÑ Îïå.
    Ïû†Ïãú(Ïòà: 2~3Ï¥à) Í∏∞Îã§Î¶¨Î©∞, Î°úÎ¥áÏù¥ "ÎÑ§?" ÌïòÍ≥† ÎêòÎ¨ºÏùÑÏßÄ Í∞ÑÏùÑ Î≥¥Îäî ÏÉÅÌÉú.
    """
    def __init__(self, engine):
        super().__init__(engine)
        self.start_time = 0.0
        self.has_llm_result = False
        self.generated_text = None

    def on_enter(self):
        logging.info("--- STATE: [Hesitating] ÎààÏπò Î≥¥Îäî Ï§ë... ---")
        self.start_time = time.time()
        
        # 1. LLMÏóê "ÎÑ§?" Í∞ôÏùÄ Î≥µÍµ¨ Î©òÌä∏ ÏÉùÏÑ± ÏöîÏ≤≠
        self.engine.llm_manager.request_hesitation()

    def update(self, chunk):
        # 1. ÏÇ¨Ïö©ÏûêÍ∞Ä Îã§Ïãú ÎßêÌïòÎäîÏßÄ Í∞êÏãú (VAD On)
        if chunk is not None:
             self.engine.stt_pre_buffer.append(chunk) # Î≤ÑÌçºÎßÅ Ï∂îÍ∞Ä
             if self.engine.vad_processor.process(chunk):
                logging.info("üó£Ô∏è ÏÇ¨Ïö©ÏûêÍ∞Ä Îã§Ïãú ÎßêÌï® -> Ï¶âÏãú Îì£Í∏∞")
                
                # ÏÉùÏÑ± Ï§ëÏù¥Îçò LLM Ï∑®ÏÜå
                self.engine.llm_manager.cancel()

                return ListeningState(self.engine, is_interruption=True)
        
        # 2. LLM Í≤∞Í≥º ÌôïÏù∏ (Non-blocking)
        if not self.has_llm_result:
            try:
                result_pkg = self.engine.llm_manager.response_queue.get_nowait()
                if result_pkg and result_pkg.get("text"):
                    self.generated_text = result_pkg["text"]
                    self.has_llm_result = True
                    logging.info(f"ü§î Î©òÌä∏ Ï§ÄÎπÑÎê®: {self.generated_text}")
            except queue.Empty:
                pass

        # 3. ÎààÏπò Î≥¥Í∏∞ ÌÉÄÏûÑÏïÑÏõÉ Ï≤òÎ¶¨
        # ÏÉÅÌô©: ÏÇ¨Ïö©ÏûêÍ∞Ä Ï°∞Ïö©Ìï® + LLM Î©òÌä∏ÎèÑ Ï§ÄÎπÑÎê® -> ÎßêÌïòÍ∏∞ ÏãúÎèÑ
        elapsed = time.time() - self.start_time
        
        if elapsed > 2.0:
            if self.has_llm_result:
                # Î©òÌä∏Í∞Ä Ï§ÄÎπÑÎêêÏúºÎ©¥ -> SpeakingStateÎ°ú Ï†ÑÌôò
                logging.info("‚è≥ Ïπ®Î¨µ ÏßÄÏÜç -> Î≥µÍµ¨ Î©òÌä∏ Î∞úÌôî")

                self.engine.history_manager.add_message({"role": "assistant", "content": self.generated_text, "type": "message"})
                return ThinkingState(self.engine, pre_generated_text=self.generated_text)
            
            elif elapsed > 10.0:
                # 10Ï¥àÍ∞Ä ÏßÄÎÇ¨ÎäîÎç∞ÎèÑ LLMÏù¥ Ïïà ÎÇòÏò§Í±∞ÎÇò ÏÇ¨Ïö©ÏûêÍ∞Ä Ï°∞Ïö©ÌïòÎ©¥
                logging.info("‚è≥ ÎÑàÎ¨¥ Ïò§Îûò Í±∏Î¶º -> Í∑∏ÎÉ• ÎåÄÍ∏∞(Idle)Î°ú Î≥µÍ∑Ä")
                self.engine.llm_manager.cancel()
                return IdleState(self.engine)

        return None

    def on_exit(self):
        pass


class ThinkingState(ConversationState):
    """
    LLM ÏÉùÏÑ± ~ TTS Î≤ÑÌçºÎßÅ ~ Ïû¨ÏÉù ÏãúÏûë ÏßÅÏ†ÑÍπåÏßÄ.
    ÎÅºÏñ¥Îì§Í∏∞ Í∞ÄÎä•
    """
    def __init__(self, engine, query_text=None, pre_generated_text=None):
        super().__init__(engine)
        self.query_text = query_text
        self.pre_generated_text = pre_generated_text
        self.step = "LLM" # LLM | TTS_BUFFER
        self.led_task = None

    def on_enter(self):
        logging.info("--- STATE: [Thinking] ÎãµÎ≥Ä ÏÉùÏÑ± Ï§ë... ---")
        if self.pre_generated_text:
            # 1. Ïù¥ÎØ∏ ÌÖçÏä§Ìä∏Í∞Ä ÏûàÏúºÎ©¥ LLM ÏÉùÎûµÌïòÍ≥† Î∞îÎ°ú TTS
            logging.info(f"üöÄ ÎØ∏Î¶¨ ÏÉùÏÑ±Îêú ÌÖçÏä§Ìä∏ ÏÇ¨Ïö©: {self.pre_generated_text}")
            self.engine.tts_manager.speak(self.pre_generated_text)
            self.step = "TTS_BUFFER"
            self.post_action = None
        else:
            if self.engine.main_loop:
                # LED: Thinking Effect On
                self.led_task = self.engine.main_loop.create_task(run_scanning_led_bar(233, 233, 50))
            self.engine.llm_manager.request_generation(self.query_text)

    def update(self, chunk):
        # ÎÅºÏñ¥Îì§Í∏∞ Í∞êÏßÄ
        if chunk is not None:
            self.engine.stt_pre_buffer.append(chunk) # Î≤ÑÌçºÎßÅ Ï∂îÍ∞Ä
            if self.engine.vad_processor.process(chunk):
                logging.info("‚ö° Thinking Ï§ë ÎÅºÏñ¥Îì§Í∏∞ Î∞úÏÉù!")
                self.engine.tts_manager.stop()
                self.engine.llm_manager.cancel()
                return ListeningState(self.engine, is_interruption=True)

        if self.step == "LLM":
            try:
                result_pkg = self.engine.llm_manager.response_queue.get_nowait()

                if result_pkg:
                    self.text = result_pkg.get("text", "")
                    self.post_action = result_pkg.get("action")

                    if self.text:
                        logging.info(f"ü§ñ TTS Ï§ÄÎπÑ: {self.text[:30]}...")
                        self.engine.tts_manager.speak(self.text)
                        self.step = "TTS_BUFFER"
                    else:
                        return IdleState(self.engine)
                else:
                    return IdleState(self.engine) # ÏóêÎü¨ Ï≤òÎ¶¨
            except queue.Empty:
                pass
        
        # 2. TTS Ïû¨ÏÉù ÏãúÏûë ÎåÄÍ∏∞
        elif self.step == "TTS_BUFFER":
            if self.engine.tts_manager.playback_started_event.is_set():
                return SpeakingState(
                    self.engine, 
                    post_action=self.post_action
                )

        return None

    def on_exit(self):
        if not self.pre_generated_text:
            # LED: Thinking Effect Off
            if self.led_task and not self.led_task.done():
                self.led_task.cancel()


class SpeakingState(ConversationState):
    """
    Î°úÎ¥áÏù¥ ÎßêÌïòÍ≥† ÏûàÎäî ÏÉÅÌÉú.
    ÎÅºÏñ¥Îì§Í∏∞ Í∞ÄÎä• (VAD Í∞êÏãú)
    """
    def __init__(self, engine, post_action=None):
        super().__init__(engine)
        self.post_action = post_action
        self.speaking_mode = "NORMAL" # NORMAL | MUSIC
    
    def on_enter(self):
        logging.info("--- STATE: [Speaking] Î∞úÌôî Ï§ë... ---")
        # LED: Î∞úÌôî Ï§ë Ïù¥ÌéôÌä∏ (Bar/Ring Yellow)
        led_set_dual((233, 233, 50), (233, 233, 50))
        self.engine.vad_processor.reset()
        self.engine.robot_finished_speaking = False

    def update(self, chunk):
        # 1. ÎÅºÏñ¥Îì§Í∏∞ Í∞êÏßÄ
        if chunk is not None:
            self.engine.stt_pre_buffer.append(chunk) # Î≤ÑÌçºÎßÅ Ï∂îÍ∞Ä
            if self.engine.vad_processor.process(chunk):
                logging.info("‚ö° Speaking Ï§ë ÎÅºÏñ¥Îì§Í∏∞ Î∞úÏÉù!")
                self.engine.tts_manager.stop()
                self.engine.history_manager.add_message({"role": "system", "content": "ÎÅºÏñ¥Îì§Í∏∞ Í∞êÏßÄ. Î∞úÌôî Ï§ëÎã®.", "type": "message"})
                return ListeningState(self.engine, is_interruption=True)

        # 2. Î°úÎ¥á ÎèôÏûë Ï¢ÖÎ£å ÌôïÏù∏ (C++ ÏãúÍ∑∏ÎÑê)
        if self.engine.robot_finished_speaking:
            logging.info("‚úÖ Î°úÎ¥á Î∞úÌôî Î∞è Î™®ÏÖò Ï¢ÖÎ£å (Signal Received)")
            self.engine.robot_finished_speaking = False

            # ÌõÑÏÜç Ïï°ÏÖò(ÎÖ∏Îûò)Ïù¥ ÏûàÎã§Î©¥ Ï≤òÎ¶¨
            if self.post_action and self.speaking_mode == "NORMAL":
                self._handle_post_action()
                self.speaking_mode = "MUSIC"
                return None # ÏùåÏïÖ Ïû¨ÏÉù Ï§ëÏóêÎäî Í≥ÑÏÜç Ïù¥ ÏÉÅÌÉú Ïú†ÏßÄ
            
            return IdleState(self.engine)

        return None
    
    def _handle_post_action(self):
        """ÎÖ∏Îûò Ïû¨ÏÉù Ï†Ñ Î™®ÏÖò ÏÉùÏÑ± ÌôïÏù∏ Î∞è Î™ÖÎ†π Ï†ÑÏÜ°"""
        logging.info("üéµ ÌõÑÏÜç Ïï°ÏÖò(ÏùåÏïÖ Ïû¨ÏÉù) Ï§ÄÎπÑ Ï§ë...")
        motion_thread = self.post_action.get("motion_thread")

        # 1. Î™®ÏÖò ÏÉùÏÑ± Ïä§Î†àÎìúÍ∞Ä ÏûàÎã§Î©¥ ÏôÑÎ£å ÎåÄÍ∏∞ (Join)
        if motion_thread and motion_thread.is_alive():
            logging.info("‚öôÔ∏è Î™®ÏÖò ÏÉùÏÑ± ÏôÑÎ£å ÎåÄÍ∏∞ (Join)...")
            motion_thread.join()
            logging.info("‚öôÔ∏è Î™®ÏÖò ÏÉùÏÑ± ÏôÑÎ£å.")

        # 2. ÏõπÏÜåÏºìÏúºÎ°ú Ïû¨ÏÉù Î™ÖÎ†π Ï†ÑÏÜ°
        audio_name = self.post_action.get("audio_name")
        if audio_name:
            if self.engine.websocket:
                asyncio.run_coroutine_threadsafe(
                    self.engine.websocket.send(json.dumps({"type": "play_audio_csv", "audio_name": audio_name})),
                    self.engine.main_loop
                )
            logging.info(f"üöÄ ÏùåÏïÖ Ïû¨ÏÉù Î™ÖÎ†π Ï†ÑÏÜ°: {audio_name}")

    def on_exit(self):
        pass


# ==================================================================================
# 3. Context (Engine)
# ==================================================================================

class ConversationEngine:
    def __init__(self, websocket, main_loop):
        logging.info("Ï¥àÍ∏∞Ìôî ÏãúÏûë")
        self.websocket = websocket
        self.main_loop = main_loop # asyncio loop (for websocket thread-safety)

        # 1. ÏÑ§Ï†ï Î°úÎìú
        self.sample_rate = AUDIO_CONFIG['SAMPLE_RATE']
        self.chunk_size = AUDIO_CONFIG['VAD_CHUNK_SIZE']

        # ÌÇ§ÏõåÎìú ÏÑ§Ï†ï
        self.start_keyword = START_KEYWORD
        self.end_keywords = END_KEYWORDS
        self.active_timeout = ACTIVE_SESSION_TIMEOUT

        # 2. Îç∞Ïù¥ÌÑ∞ ÌÅê Ï¥àÍ∏∞Ìôî
        self.mic_queue = queue.Queue()
        self.stt_audio_queue = queue.Queue()
        self.stt_result_queue = queue.Queue()

        # 3. Î≤ÑÌçº Ï¥àÍ∏∞Ìôî
        # Pre-buffer: Î∞úÌôî Í∞êÏßÄ Ï†Ñ 0.5Ï¥à Ï†ïÎèÑÏùò Ïò§ÎîîÏò§Î•º Ï†ÄÏû• (dequeÎ°ú ÏûêÎèô Í∏∏Ïù¥ Í¥ÄÎ¶¨)
        pre_buffer_len = math.ceil(self.sample_rate * 0.5 / self.chunk_size)
        self.stt_pre_buffer = deque(maxlen=pre_buffer_len)

        # 4. ÎèÑÍµ¨(Tools) Ï¥àÍ∏∞Ìôî
        self.vad_processor = VADProcessor(
            sample_rate=self.sample_rate,
            chunk_size=self.chunk_size,
            threshold=AUDIO_CONFIG['VAD_THRESHOLD'],
            consecutive_chunks=AUDIO_CONFIG['VAD_CONSECUTIVE_CHUNKS'],
            reset_interval=AUDIO_CONFIG['VAD_RESET_INTERVAL']
        )
        
        self.smart_turn_processor = SmartTurnProcessor(SMART_TURN_MODEL_PATH)

        # 5. Îß§ÎãàÏ†Ä(Managers) Ï¥àÍ∏∞Ìôî
        self.history_manager = ConversationManager(openai_api_key=OPENAI_API_KEY)

        self.llm_manager = LLMManager(
            openai_api_key=OPENAI_API_KEY,
            conversation_manager=self.history_manager,
            main_loop=self.main_loop,
            websocket=self.websocket
        )
        
        self.tts_manager = TTSManager(
            openai_api_key=OPENAI_API_KEY,
            main_loop=self.main_loop,
            websocket=self.websocket
        )

        # 6. STT Ïä§Ìä∏Î¶¨Î®∏ Ï¥àÍ∏∞Ìôî
        self.stt_stop_event = threading.Event()
        self.stt_streamer = GoogleSTTStreamer(
            stt_result_queue=self.stt_result_queue,
            main_loop=self.main_loop,
            websocket=self.websocket,
            sample_rate=self.sample_rate,
            stt_audio_queue=self.stt_audio_queue,
            stt_stop_event=self.stt_stop_event
        )

        # 7. ÎßàÏù¥ÌÅ¨ Ïä§Ìä∏Î¶º Ï¥àÍ∏∞Ìôî
        self.mic_stream = MicrophoneStream(
            mic_audio_queue=self.mic_queue,
            sample_rate=self.sample_rate,
            chunk_size=self.chunk_size,
            channels=AUDIO_CONFIG['CHANNELS'],
            dtype=AUDIO_CONFIG['AUDIO_DTYPE'],
            device_idx=find_input_device()
        )

        # 8. ÏÉÅÌÉú Ï¥àÍ∏∞Ìôî
        self._current_state = SleepState(self)
        self._is_running = False
        self.robot_finished_speaking = False

    def on_robot_finished(self):
        """C++Î°úÎ∂ÄÌÑ∞ ÎßêÌïòÍ∏∞ Ï¢ÖÎ£å Ïã†Ìò∏ ÏàòÏã†"""
        logging.info("ü§ñ Robot finished speaking signal received")
        self.robot_finished_speaking = True

    async def start(self):
        logging.info("üöÄ ConversationEngine ÏãúÏûë")
        self._is_running = True

        # ÎßàÏù¥ÌÅ¨ Ï∫°Ï≤ò ÏãúÏûë (Background Thread inside sounddevice)
        self.mic_stream.start()

        # Ï¥àÍ∏∞ ÏÉÅÌÉú ÏßÑÏûÖ
        self._current_state.on_enter()
        
        try:
            await self._loop()
        except asyncio.CancelledError:
            logging.info("ÏóîÏßÑ ÏûëÏóÖ Ï∑®ÏÜåÎê®")
        except KeyboardInterrupt:
            logging.info("ÌÇ§Î≥¥Îìú Ïù∏ÌÑ∞ÎüΩÌä∏ Í∞êÏßÄ")
        finally:
            self.stop()
    
    def stop(self):
        """ÏóîÏßÑ Ï¢ÖÎ£å Î∞è Î¶¨ÏÜåÏä§ Ï†ïÎ¶¨"""
        logging.info("üõë ConversationEngine Ï¢ÖÎ£å Ï§ë...")
        self._is_running = False
        
        # ÎßàÏù¥ÌÅ¨ Ï§ëÏßÄ
        if self.mic_stream:
            self.mic_stream.stop()
        
        # Îß§ÎãàÏ†Ä/Ïä§Î†àÎìú Ï†ïÎ¶¨
        self.stt_stop_event.set()
        self.stt_audio_queue.put(None)
        self.llm_manager.cancel()
        self.tts_manager.stop()
        
        logging.info("‚úÖ Ï¢ÖÎ£å ÏôÑÎ£å")

    async def _loop(self):
        """Î©îÏù∏ Ïò§ÎîîÏò§ Ï≤òÎ¶¨ Î£®ÌîÑ"""
        while self._is_running:
            await asyncio.sleep(0.01)

            try:
                # 1. ÎßàÏù¥ÌÅ¨ ÏûÖÎ†• (Blocking w/ Timeout)
                chunk = self.mic_queue.get_nowait()
            except queue.Empty:
                chunk = None # Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏñ¥ÎèÑ updateÎäî Ìò∏Ï∂úÌï¥Ïïº Ìï® (ÌÉÄÏù¥Î®∏ Î°úÏßÅ Îì±)

            # 2. ÌòÑÏû¨ ÏÉÅÌÉú ÏóÖÎç∞Ïù¥Ìä∏
            next_state = self._current_state.update(chunk)

            # 3. ÏÉÅÌÉú Ï†ÑÏù¥
            if next_state:
                self._transition(next_state)

    def _transition(self, new_state):
        prev_name = self._current_state.__class__.__name__
        next_name = new_state.__class__.__name__
        logging.info(f"üîÑ ÏÉÅÌÉú Ï†ÑÏù¥: {prev_name} -> {next_name}")

        self._current_state.on_exit()
        self._current_state = new_state
        self._current_state.on_enter()

async def test():
    logging.info("test ÏãúÏûë")
    engine = ConversationEngine(websocket=None, main_loop=asyncio.get_running_loop())
    await engine.start()

if __name__ == "__main__":
    asyncio.run(test())