from collections import deque
import math
import os
import sys
import time
import json
import queue
import base64
import logging
import asyncio
import threading
import numpy as np
from abc import ABC, abstractmethod

from led import led_set_ring
from conversation_manager import ConversationManager
from offline_motion import offline_motion_generation

from audio_processor import VADProcessor, SmartTurnProcessor, GoogleSTTStreamer, MicrophoneStream, find_input_device

from config import (
    SMART_TURN_MODEL_PATH,
    TURN_END_SILENCE_CHUNKS,
    MAX_TURN_CHUNKS,
    SMART_TURN_GRACE_PERIOD,
    STT_WAIT_TIMEOUT_SECONDS,
    SLEEP_FILE, AWAKE_FILE, ACTIVE_SESSION_TIMEOUT, START_KEYWORD, END_KEYWORDS,
    TTS_MODEL, VOICE, RESPONSES_MODEL, RESPONSES_PRESETS, AUDIO_CONFIG, ASSETS_DIR, OPENAI_API_KEY
)
from prompts import SYSTEM_PROMPT_RESP_ONLY

from openai import OpenAI

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] [%(threadName)s] %(message)s',
    datefmt='%H:%M:%S',
    handlers=[logging.StreamHandler(sys.stdout)],
    force=True
)


async def run_thinking_led_spin(r, g, b, speed=4.0, focus=10.0):
    """
    LLM ìƒê° ì¤‘ í‘œì‹œë¥¼ ìœ„í•œ ë¹„ë™ê¸° LED ì• ë‹ˆë©”ì´ì…˜ (ì›í˜• íšŒì „).
    ThinkingStateì—ì„œ asyncio.create_taskë¡œ ì‹¤í–‰ë¨.
    """
    if not strip:
        return
    
    ring_size = 8
    top_offset = 8
    bottom_offset = 16
    start_shift = 4 

    try:
        while True:
            t = time.time() * speed
            
            for i in range(ring_size):
                # ê°ë„ ë° íŒŒë™ ê³„ì‚°
                angle = ((i - start_shift) / ring_size) * 2 * math.pi
                wave = math.sin(t + angle)
                
                # ë°ê¸° ê³„ì‚° (0 ~ 1)
                brightness = (wave + 1) / 2
                brightness = math.pow(brightness, focus)
                
                # ìƒ‰ìƒ ì ìš©
                cr = int(r * brightness)
                cg = int(g * brightness)
                cb = int(b * brightness)
                
                final_color = Color(cr, cg, cb)
                
                # ìœ„/ì•„ëž˜ ë§ ë™ì‹œ ì ìš©
                strip.set_pixel_color(top_offset + i, final_color)
                strip.set_pixel_color(bottom_offset + i, final_color)
            
            strip.show()
            await asyncio.sleep(0.02) # ì•½ 50 FPS
            
    except asyncio.CancelledError:
        # íƒœìŠ¤í¬ ì·¨ì†Œ ì‹œ í•´ë‹¹ ë§ ë„ê¸° (ë˜ëŠ” ê¸°ë³¸ ìƒ‰ìœ¼ë¡œ ë³µê·€)
        # ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ ë„ëŠ” ê²ƒìœ¼ë¡œ ì²˜ë¦¬
        for i in range(ring_size):
             strip.set_pixel_color(top_offset + i, Color(0,0,0))
             strip.set_pixel_color(bottom_offset + i, Color(0,0,0))
        strip.show()
        raise

# ==================================================================================
# LLM tools
# =================================================================================
import re

# ìŒì•… ìž¬ìƒ
with open('assets/songs_db.json', 'r') as f:
    SONG_DB = json.load(f)

def normalize_string(input_str):
    return re.sub(r'\s+', '', input_str).lower()

song_candidates = []
for song in SONG_DB:
    song_processed = song.copy()
    song_processed['norm_title'] = normalize_string(song['title'])
    song_processed['norm_artist'] = normalize_string(song['artist'])
    song_candidates.append(song_processed)

def play_music(song_title: str = "", artist_name: str = ""):
    """
    LLMì´ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜
    ì‚¬ìš©ìžê°€ ìš”ì²­í•œ ì¡°ê±´ì— ë§žëŠ” ë…¸ëž˜ë¥¼ DBì—ì„œ ê²€ìƒ‰í•˜ì—¬ ìž¬ìƒ
    """
    target_title = normalize_string(song_title)
    target_artist = normalize_string(artist_name)

    candidates = song_candidates

    if song_title:
        candidates = [s for s in candidates if target_title in s['norm_title']]

    if artist_name:
        candidates = [s for s in candidates if target_artist in s['norm_artist']]

    if candidates:
        selected_song = candidates[0]
        logging.info(f"ìž¬ìƒí•  ë…¸ëž˜ ì°¾ìŒ: '{selected_song['title']}' by {selected_song['artist']}")
        return selected_song['file_path'], f"Found and playing '{selected_song['title']}' by {selected_song['artist']}."
    else:
        logging.info("ìž¬ìƒí•  ë…¸ëž˜ë¥¼ ì°¾ì§€ ëª»í•¨.")
        return None, "ë…¸ëž˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


# ==================================================================================
# 0. ë§¤ë‹ˆì € í´ëž˜ìŠ¤ (LLM/TTS ìŠ¤ë ˆë“œ ê´€ë¦¬ìš© - ìƒˆë¡œ ì¶”ê°€ í•„ìš”)
# ==================================================================================
class LLMManager:
    def __init__(self, openai_api_key, conversation_manager, main_loop, websocket):
        self.client = OpenAI(api_key=openai_api_key)
        self.history_manager = conversation_manager
        self.main_loop = main_loop
        self.websocket = websocket
        
        # ê²°ê³¼ ì „ë‹¬ìš© í
        self.response_queue = queue.Queue()
        
        # ì‹¤í–‰ ì œì–´ìš©
        self._thread = None
        self._stop_event = threading.Event()
        self.current_request_id = 0

    def request_generation(self, user_text):
        """ThinkingStateì—ì„œ í˜¸ì¶œ: ë‹µë³€ ìƒì„± ìš”ì²­"""
        self._stop_event.clear()
        self.current_request_id += 1
        request_id = self.current_request_id
        
        # ì´ì „ í ë¹„ìš°ê¸°
        with self.response_queue.mutex:
            self.response_queue.queue.clear()
            
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        self._thread = threading.Thread(
            target=self._run_generation,
            args=(user_text, request_id),
            name="LLMThread",
            daemon=True
        )
        self._thread.start()

    def cancel(self):
        """ì¸í„°ëŸ½ì…˜ ë°œìƒ ì‹œ í˜¸ì¶œ: ìž‘ì—… ì·¨ì†Œ"""
        self._stop_event.set()
        self.current_request_id += 1 # í˜„ìž¬ ìž‘ì—… ID ë¬´íš¨í™”

    def _run_generation(self, user_text, request_id):
        try:
            # ID ê²€ì¦
            if self.current_request_id != request_id: return

            # 1. ì‚¬ìš©ìž ë©”ì‹œì§€ ê¸°ë¡
            self.history_manager.add_message("user", user_text)
            current_log = self.history_manager.get_current_log()
            
            # 2. ë„êµ¬ ì •ì˜
            tools = [
                {
                    "type": "web_search",
                    "user_location": {"type": "approximate", "country": "KR"},
                },
                {
                    "type": "function",
                    "name": "play_music",
                    "description": "ì‚¬ìš©ìžê°€ ìš”ì²­í•œ ë…¸ëž˜ë¥¼ ê²€ìƒ‰í•˜ì—¬ ìž¬ìƒí•©ë‹ˆë‹¤. ì €ìž¥ëœ DBì— ìžˆëŠ” ë…¸ëž˜ë§Œ ìž¬ìƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "song_title": {"type": "string"},
                            "artist_name": {"type": "string"},
                        },
                        "required": ["song_title", "artist_name"] 
                    }
                }
            ]

            # 3. Responses API í˜¸ì¶œ (1ì°¨)
            if self._stop_event.is_set() or self.current_request_id != request_id: return

            params = {
                **RESPONSES_PRESETS.get(RESPONSES_MODEL, {}),
                "input": current_log,
                "tools": tools,
            }
            response = self.client.responses.create(**params)
            
            final_text = ""
            music_action = None
            motion_thread = None

            # 4. Responses ê²°ê³¼ ì²˜ë¦¬ ë£¨í”„
            for item in response.output:
                if self._stop_event.is_set() or self.current_request_id != request_id: return

                if item.type == "function_call":
                    logging.info(f"ðŸ§  Function call: {item.name}")

                    if item.name == "play_music":
                        args = json.loads(item.arguments)
                        song_title = args.get("song_title", "")
                        artist_name = args.get("artist_name", "")

                        # (1) ë…¸ëž˜ ì°¾ê¸°
                        file_path, message = play_music(song_title, artist_name)
                        status = "failure"

                        if file_path:
                            status = "success"
                            audio_name = f"{song_title}_{artist_name}"
                            csv_path = os.path.join(ASSETS_DIR, "headMotion", f"{audio_name}.csv")

                            # (2) ëª¨ì…˜ ìƒì„± (ì—†ì„ ê²½ìš°) - ìŠ¤ë ˆë“œë¡œ ë¶„ë¦¬í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬
                            if not os.path.exists(os.path.join(ASSETS_DIR, "headMotion", f"{audio_name}.csv")):
                                if not os.path.exists(csv_path):
                                    logging.info(f"âš™ï¸ ëª¨ì…˜ íŒŒì¼ ì—†ìŒ. ìƒì„± ì‹œìž‘: {audio_name}")
                                    motion_thread = threading.Thread(
                                        target=offline_motion_generation,
                                        args=(audio_name,),
                                        name="MotionGenThread"
                                    )
                                    motion_thread.start()
                            
                            # ì•¡ì…˜ ì •ë³´ ì €ìž¥
                            music_action = {"audio_name": audio_name, "motion_thread": motion_thread}
                        
                        # (3) ê²°ê³¼ ížˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (ìž¬ìš”ì²­ì„ ìœ„í•´)
                        current_log_copy = current_log.copy()
                        current_log_copy.append(item)
                        current_log_copy.append({
                            "type": "function_call_output",
                            "call_id": item.call_id,
                            "output": json.dumps({"status": status, "message": message})
                        })

                        # (4) 2ì°¨ Responses API í˜¸ì¶œ (ê²°ê³¼ ë©˜íŠ¸ ìƒì„±)
                        params["input"] = current_log_copy
                        response_2 = self.client.responses.create(**params)
                        final_text = response_2.output[0].content[0].text.strip()
                        break

                elif item.type == "message":
                    final_text = item.content[0].text.strip()
                    break


            # 5. ê²°ê³¼ ë°˜í™˜
            if self._stop_event.is_set() or self.current_request_id != request_id: return

            logging.info(f"ðŸ§  ë‹µë³€ ìƒì„± ì™„ë£Œ: {final_text}")
            result_package = {"text": final_text, "action": music_action}

            if self.current_request_id == request_id:
                self.response_queue.put(result_package)

        except Exception as e:
            logging.error(f"âŒ LLM ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            if self.current_request_id == request_id:
                self.response_queue.put(None)

    def request_hesitation(self):
        """HesitatingStateì—ì„œ í˜¸ì¶œ: ë³µêµ¬ ë©˜íŠ¸ ìƒì„± ìš”ì²­"""
        self._stop_event.clear()
        self.current_request_id += 1
        request_id = self.current_request_id
        
        # í ë¹„ìš°ê¸°
        with self.response_queue.mutex:
            self.response_queue.queue.clear()
            
        self._thread = threading.Thread(
            target=self._run_hesitation,
            args=(request_id,),
            name="HesitationLLMThread",
            daemon=True
        )
        self._thread.start()

    def _run_hesitation(self, request_id):
        try:
            if self.current_request_id != request_id: return

            # 1. í˜„ìž¬ ë¡œê·¸ ê°€ì ¸ì˜¤ê¸° (ì›ë³¸)
            current_log = self.history_manager.get_current_log()
            
            # 2. ìž„ì‹œ ë¡œê·¸ ìƒì„± (ë³µì‚¬ë³¸ì— ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€)
            # ì£¼ì˜: ë¦¬ìŠ¤íŠ¸ë¥¼ ì–•ì€ ë³µì‚¬(copy())í•´ì„œ ì›ë³¸ historyì—ëŠ” ì˜í–¥ ì—†ê²Œ í•¨
            temp_log = current_log.copy()
            
            # ìƒí™© ì„¤ëª… ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì£¼ìž…
            system_instruction = {
                "role": "system",
                "content": (
                    "ìƒí™©: ì‚¬ìš©ìžê°€ ë¡œë´‡ì˜ ë§ì„ ëŠê³  ë¬´ì–¸ê°€ ë§í•˜ë ¤ í–ˆìœ¼ë‚˜, ë¡œë´‡ì´ ì œëŒ€ë¡œ ì•Œì•„ë“£ì§€ ëª»í–ˆìŠµë‹ˆë‹¤(STT ì‹¤íŒ¨/ì¹¨ë¬µ). "
                    "ì§€ì¹¨: ì‚¬ìš©ìžê°€ ë‹¤ì‹œ ë§í•˜ë„ë¡ ìžì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•˜ëŠ” ì§§ì€ ë¬¸ìž¥ì„ ìƒì„±í•˜ì„¸ìš”. "
                    "ì˜ˆì‹œ: 'ì£„ì†¡í•´ìš”, ë°©ê¸ˆ ë§ì”€ì„ ë†“ì³¤ì–´ìš”.', 'ë„¤? ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?' 'ì´ì–´ì„œ ë§í•´ë„ ë ê¹Œìš”?' "
                    "ì£¼ì˜: ì•„ì£¼ ì§§ê³  ì •ì¤‘í•˜ê²Œ, 15ìž ì´ë‚´ë¡œ."
                )
            }
            temp_log.append(system_instruction)

            # 3. Responses API í˜¸ì¶œ
            if self._stop_event.is_set() or self.current_request_id != request_id: return

            params = {
                **RESPONSES_PRESETS.get(RESPONSES_MODEL, {}),
                "model": RESPONSES_MODEL,
                "input": temp_log,
                # Hesitationì—ì„œëŠ” ë„êµ¬(Tools) ì‚¬ìš© ì•ˆ í•¨ (ë‹¨ìˆœ ë°œí™”ë§Œ)
            }

            response = self.client.responses.create(**params)
            
            final_text = response.output[0].content[0].text.strip()

            # 4. ê²°ê³¼ ì²˜ë¦¬
            if not self._stop_event.is_set() and final_text and self.current_request_id == request_id:
                logging.info(f"ðŸ¤” ë³µêµ¬ ë©˜íŠ¸ ìƒì„±: {final_text}")
                
                # ì—¬ê¸°ì„œëŠ” Historyì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ.
                # ë‚˜ì¤‘ì— SpeakingStateë¡œ ë„˜ì–´ê°ˆ ë•Œ(í™•ì •ë  ë•Œ) ì¶”ê°€í•˜ê±°ë‚˜,
                # ì•„ë‹ˆë©´ ê·¸ëƒ¥ ì‹œìŠ¤í…œ ë©˜íŠ¸ë‹ˆê¹Œ Historyì— ì•ˆ ë‚¨ê¸°ëŠ” ê²Œ ê¹”ë”í•  ìˆ˜ ìžˆìŒ.
                # (ë³´í†µ "ë„¤?" ê°™ì€ ì¶”ìž„ìƒˆëŠ” ì•ˆ ë‚¨ê¸°ëŠ” ê²Œ ëª¨ë¸ ì„±ëŠ¥ì— ì¢‹ìŒ)
                
                # ê²°ê³¼ íŒ¨í‚¤ì§€ (Action ì—†ìŒ)
                result_package = {
                    "text": final_text,
                    "action": None,
                    "is_hesitation": True # í”Œëž˜ê·¸ ì¶”ê°€
                }
                self.response_queue.put(result_package)

        except Exception as e:
            logging.error(f"âŒ Hesitation LLM ì˜¤ë¥˜: {e}")
            if self.current_request_id == request_id:
                self.response_queue.put(None)


class TTSManager:
    def __init__(self, openai_api_key, main_loop, websocket):
        self.client = OpenAI(api_key=openai_api_key)
        self.main_loop = main_loop
        self.websocket = websocket
        
        self.is_playing = False
        self.playback_started_event = threading.Event()
        self._stop_event = threading.Event()
        self._thread = None

    def speak(self, text):
        """TTS ìŠ¤íŠ¸ë¦¬ë° ì‹œìž‘ (ThinkingState í˜¸ì¶œ)"""
        self._stop_event.clear()
        self.playback_started_event.clear()
        self.is_playing = True
        
        self._thread = threading.Thread(
            target=self._run_tts,
            args=(text,),
            name="TTS_Thread",
            daemon=True
        )
        self._thread.start()

    def stop(self):
        """TTS ì¦‰ì‹œ ì¤‘ë‹¨ (SpeakingState ì¸í„°ëŸ½ì…˜ í˜¸ì¶œ)"""
        if self.is_playing:
            logging.info("ðŸ”‡ TTS ì¤‘ë‹¨ ìš”ì²­")
            self._stop_event.set() # 1. ë£¨í”„ í”Œëž˜ê·¸ ì„¤ì •
            self.is_playing = False
            
            # 2. C++ ì˜¤ë””ì˜¤ ë²„í¼ í´ë¦¬ì–´ ëª…ë ¹ (ì„ íƒ ì‚¬í•­)
            # asyncio.run_coroutine_threadsafe(
            #     self.websocket.send(json.dumps({"type": "stop_audio"})),
            #     self.main_loop
            # )

    def _run_tts(self, text):
        try:
            # 1. ìŠ¤íŠ¸ë¦¬ë° ì‹œìž‘ ì•Œë¦¼ (C++ ëª¨ì…˜ ì¤€ë¹„ ë“±)
            if self.websocket:
                asyncio.run_coroutine_threadsafe(
                    self.websocket.send(json.dumps({"type": "responses_only"})),
                    self.main_loop
                )

            # 2. OpenAI TTS í˜¸ì¶œ (Stream)
            with self.client.audio.speech.with_streaming_response.create(
                model=TTS_MODEL, voice=VOICE, input=text, response_format="pcm"
            ) as response:
                first_chunk = True

                # 3. ì²­í¬ ì „ì†¡ ë£¨í”„
                for chunk in response.iter_bytes(chunk_size=4096):
                    # ì¤‘ë‹¨ ìš”ì²­ ì²´í¬
                    if self._stop_event.is_set():
                        logging.info("ðŸ›‘ TTS ìŠ¤íŠ¸ë¦¬ë° ë£¨í”„ íƒˆì¶œ")
                        break
                    
                    # ì›¹ì†Œì¼“ ì „ì†¡
                    if self.websocket:
                        asyncio.run_coroutine_threadsafe(
                            self.websocket.send(json.dumps({
                                "type": "responses_audio_chunk",
                                "data": base64.b64encode(chunk).decode('utf-8')
                            })),
                            self.main_loop
                        )

                    # ì²« ì²­í¬ ì „ì†¡ ì‹œì ì— 'ìž¬ìƒ ì‹œìž‘' ê°„ì£¼
                    if first_chunk:
                        logging.info("ðŸ”Š TTS ì²« ì²­í¬ ì „ì†¡ -> Playback Started")
                        self.playback_started_event.set()
                        first_chunk = False

            # 4. ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì²˜ë¦¬
            if not self._stop_event.is_set():
                if self.websocket:
                    asyncio.run_coroutine_threadsafe(
                        self.websocket.send(json.dumps({"type": "responses_stream_end"})),
                        self.main_loop
                    )

        except Exception as e:
            logging.error(f"âŒ TTS ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}", exc_info=True)
        finally:
            self.is_playing = False
            # í˜¹ì‹œ ì—ëŸ¬ë‚˜ì„œ ì‹œìž‘ ì´ë²¤íŠ¸ê°€ ì•ˆ ì¼œì¡Œìœ¼ë©´, ë¬´í•œ ëŒ€ê¸° ë°©ì§€ë¥¼ ìœ„í•´ ì¼œì¤Œ
            if not self.playback_started_event.is_set():
                self.playback_started_event.set()

# ==================================================================================
# 1. State Interface
# ==================================================================================
class ConversationState(ABC):
    def __init__(self, engine):
        self.engine = engine

    @abstractmethod
    def on_enter(self):
        """ìƒíƒœ ì§„ìž… ì‹œ 1íšŒ ì‹¤í–‰"""
        pass

    @abstractmethod
    def update(self, chunk: np.ndarray) -> 'ConversationState | None':
        """
        ë©”ì¸ ë£¨í”„ì—ì„œ ì£¼ê¸°ì ìœ¼ë¡œ í˜¸ì¶œë¨.
        - chunk: ë§ˆì´í¬ ìž…ë ¥ (VAD ë¶„ì„ìš©)
        - return: ìƒíƒœ ì „ì´ê°€ í•„ìš”í•˜ë©´ State ê°ì²´ ë°˜í™˜, ì•„ë‹ˆë©´ None
        """
        pass

    @abstractmethod
    def on_exit(self):
        """ìƒíƒœ íƒˆì¶œ ì‹œ 1íšŒ ì‹¤í–‰"""
        pass

# ==================================================================================
# 2. State Implementations
# ==================================================================================

class SleepState(ConversationState):
    """
    ì‹œìž‘ í‚¤ì›Œë“œë§Œ ê¸°ë‹¤ë¦¬ëŠ” ëŒ€ê¸° ìƒíƒœ.
    """
    def on_enter(self):
        logging.info("STATE: [Sleep] ì‹œìž‘ í‚¤ì›Œë“œ ëŒ€ê¸° ì¤‘... (ZZZ)")
        # LED Off or Dimmed
        self.engine.vad_processor.reset()
        
        # í ë¹„ìš°ê¸°
        with self.engine.stt_audio_queue.mutex:
            self.engine.stt_audio_queue.queue.clear()

    def update(self, chunk):
        if chunk is None: return None

        # 1. ë²„í¼ë§ (í‚¤ì›Œë“œ ì•žë¶€ë¶„ ìž˜ë¦¼ ë°©ì§€)
        self.engine.stt_pre_buffer.append(chunk)

        # 2. VAD ê°ì§€
        if self.engine.vad_processor.process(chunk):
            logging.info("ðŸ’¤ Sleep ì¤‘ ë°œí™” ê°ì§€ -> í‚¤ì›Œë“œ í™•ì¸(Listening) ëª¨ë“œ ì§„ìž…")
            
            return ListeningState(self.engine, mode="WAKEWORD")
            
        return None

    def on_exit(self):
        pass


class IdleState(ConversationState):
    def on_enter(self):
        logging.info("STATE: [Idle] ëŒ€ê¸° ì‹œìž‘")
        led_set_ring(233, 233, 50)

        # VAD ìƒíƒœ ë¦¬ì…‹ (ì´ì „ ìž¡ìŒ ì˜í–¥ ì œê±°)
        self.engine.vad_processor.reset()
        self.last_activity_time = time.time()

    def update(self, chunk):
        if chunk is not None:
            self.engine.stt_pre_buffer.append(chunk)

            # ë°œí™” ê°ì§€
            if self.engine.vad_processor.process(chunk):
                logging.info("ðŸ—£ï¸ ë°œí™” ì‹œìž‘ ê°ì§€")
                return ListeningState(self.engine, is_interruption=False, mode="NORMAL")
    
        # íƒ€ìž„ì•„ì›ƒ ê°ì§€
        if time.time() - self.last_activity_time > self.engine.active_timeout:
            logging.info(f"â° {self.engine.active_timeout}ì´ˆê°„ ìž…ë ¥ ì—†ìŒ -> Sleep ì „í™˜")

            # ì¢…ë£Œ ì‚¬ìš´ë“œ ìž¬ìƒ
            if self.engine.websocket:
                asyncio.run_coroutine_threadsafe(
                    self.engine.websocket.send(json.dumps({"type": "play_audio", "file_to_play": str(SLEEP_FILE)})),
                    self.engine.main_loop
                )
            self.engine.history_manager.end_session()
            return SleepState(self.engine)
        
        return None

    def on_exit(self):
        pass


class ListeningState(ConversationState):
    def __init__(self, engine, is_interruption=False, mode="NORMAL"):
        super().__init__(engine)
        self.is_interruption = is_interruption
        self.mode = mode # NORMAL | WAKEWORD

        # í˜„ìž¬ í„´ ì˜¤ë””ì˜¤ ë²„í¼ (SmartTurnìš©)
        self.audio_buffer = []

        # í„´ ê°ì§€ ê´€ë ¨ ë³€ìˆ˜
        self.silent_chunks = 0
        self.turn_mode = "LISTENING" # LISTENING | GRACE
        self.grace_period_end_time = None

        # STT ìŠ¤ë ˆë“œ í•¸ë“¤
        self.stt_thread = None

    def on_enter(self):
        logging.info(f"STATE: [Listening] (Interruption={self.is_interruption})")

        # LED
        if self.mode == "NORMAL":
            led_set_ring(233,233,50)

        # 1. í ì´ˆê¸°í™” (ì´ì „ í„´ì˜ ìž”ì—¬ ë°ì´í„° ì œê±°)
        with self.engine.stt_audio_queue.mutex:
            self.engine.stt_audio_queue.queue.clear()
        
        with self.engine.stt_result_queue.mutex:
            self.engine.stt_result_queue.queue.clear()

        # 2. STT ì‹œìž‘
        self.engine.stt_stop_event.clear()
        self.stt_thread = threading.Thread(
            target=self.engine.stt_streamer.run_stt_session,
            name="STTSessionThread",
            daemon=True
        )
        self.stt_thread.start()

        # 3. Pre-buffer ì²˜ë¦¬
        # Engineì— ìžˆëŠ” ë²„í¼ë¥¼ í„¸ì–´ì„œ STT íì™€ ë‚´ ë²„í¼ì— ë„£ìŒ
        if self.engine.stt_pre_buffer:
            for chunk in self.engine.stt_pre_buffer:
                self.engine.stt_audio_queue.put(chunk)
                self.audio_buffer.append(chunk)
            self.engine.stt_pre_buffer.clear() # ì²˜ë¦¬ í–ˆìœ¼ë‹ˆ ë¹„ì›€
        
        # 4. ì¸í„°ëŸ½ì…˜ ì‹ í˜¸ ì „ì†¡
        if self.is_interruption and self.engine.websocket:
            # C++ë¡œ ì¸í„°ëŸ½ì…˜ ì‹ í˜¸ ì „ì†¡
            asyncio.run_coroutine_threadsafe(
                self.engine.websocket.send(json.dumps({"type": "user_interruption"})),
                self.engine.main_loop
            )

    def update(self, chunk):
        if chunk is None: return None

        # 1. ì˜¤ë””ì˜¤ ë°ì´í„° ê³µê¸‰
        self.engine.stt_audio_queue.put(chunk)
        self.audio_buffer.append(chunk)

        # 2. VAD ë¶„ì„
        is_speech = self.engine.vad_processor.process(chunk)

        if is_speech:
            self.silent_chunks = 0
            if self.turn_mode == "GRACE":
                logging.info("ðŸ”„ ìœ ì˜ˆ ì‹œê°„ ì¤‘ ìž¬ë°œí™” -> ê³„ì† ë“£ê¸°")
                self.turn_mode = "LISTENING"
                self.grace_period_end_time = None
        else:
            self.silent_chunks += 1

        # 3. í„´ ì¢…ë£Œ íŒë‹¨
        # [Case A] ìœ ì˜ˆ ì‹œê°„ ëª¨ë“œ
        if self.turn_mode == "GRACE":
            if time.time() >= self.grace_period_end_time:
                logging.info("â³ ìœ ì˜ˆ ì‹œê°„ ì¢…ë£Œ -> í„´ ì¢…ë£Œ í™•ì •")
                return self._finish_listening()
            return None
        
        # [Case B] ì¼ë°˜ ë“£ê¸° ëª¨ë“œ (VAD ì¹¨ë¬µ ì§€ì† ì‹œ)
        if self.silent_chunks > TURN_END_SILENCE_CHUNKS:
            prediction = self._run_smart_turn()
            
            if prediction == 1: # [ì¢…ë£Œ]
                logging.info("ðŸ¤– SmartTurn: ì¢…ë£Œ(1) ì˜ˆì¸¡")
                return self._finish_listening()
            
            elif prediction == 0: # [ì§„í–‰ì¤‘]
                logging.info(f"ðŸ¤– SmartTurn: ì§„í–‰ì¤‘(0) ì˜ˆì¸¡ -> ìœ ì˜ˆ ì§„ìž… ({SMART_TURN_GRACE_PERIOD}s)")
                self.turn_mode = "GRACE"
                self.grace_period_end_time = time.time() + SMART_TURN_GRACE_PERIOD
                self.silent_chunks = 0 # ì¤‘ë³µ ì²´í¬ ë°©ì§€

        return None

    def _run_smart_turn(self):
        # Stateê°€ ê´€ë¦¬í•˜ëŠ” audio_buffer ì‚¬ìš©
        if not self.audio_buffer: return 0
        
        concatenated = np.concatenate([c.flatten() for c in self.audio_buffer])
        full_audio = concatenated.astype(np.float32) / 32768.0
        
        result = self.engine.smart_turn_processor.predict(full_audio)
        return result['prediction']
    
    def _finish_listening(self):
        """ë“£ê¸° ì¢…ë£Œ í›„ ë‹¤ìŒ ìƒíƒœ ê²°ì •"""
        return SttResultWaitingState(
            self.engine, 
            was_interruption=self.is_interruption,
            mode=self.mode
        )

    def on_exit(self):
        logging.info("ðŸ›‘ Listening ì¢…ë£Œ -> STT ì¤‘ë‹¨ ì‹ í˜¸")
        self.engine.stt_stop_event.set()
        self.engine.stt_audio_queue.put(None)


class SttResultWaitingState(ConversationState):
    """STT ì„œë²„ë¡œë¶€í„° ìµœì¢… ê²°ê³¼ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ìƒíƒœ"""
    def __init__(self, engine, was_interruption, mode="NORMAL"):
        super().__init__(engine)
        self.was_interruption = was_interruption
        self.mode = mode # NORMAL | WAKEWORD

        self.start_time = 0.0

    def on_enter(self):
        logging.info("STATE: [SttResultWaiting] STT ê²°ê³¼ ëŒ€ê¸°ì¤‘...")
        self.start_time = time.time()

    def update(self, chunk):
        # ì˜¤ë””ì˜¤ ì²­í¬ëŠ” ë¬´ì‹œ
        
        # 1. STT ê²°ê³¼ í í™•ì¸ (Non-blocking)
        try:
            text = self.engine.stt_result_queue.get_nowait()
            
            if text is None:
                # STT ì‹¤íŒ¨ ì‹ í˜¸ ìˆ˜ì‹  -> ì¦‰ì‹œ ì‹¤íŒ¨ ì²˜ë¦¬
                logging.info("STT ì¸ì‹ ì‹¤íŒ¨(None) ìˆ˜ì‹ ")
                return self._handle_failure()
            
            logging.info(f"ðŸ“ STT ê²°ê³¼: '{text}' (Mode={self.mode})")

            if self.mode == "WAKEWORD":
                if self.engine.start_keyword in text:
                    logging.info(f"âœ¨ ì‹œìž‘ í‚¤ì›Œë“œ ê°ì§€! -> Active ëª¨ë“œ ì‹œìž‘")
                
                    # 1. ê¹¨ì–´ë‚¨ ì‚¬ìš´ë“œ ìž¬ìƒ
                    if self.engine.websocket:
                        asyncio.run_coroutine_threadsafe(
                            self.engine.websocket.send(json.dumps({"type": "play_audio", "file_to_play": str(AWAKE_FILE)})),
                            self.engine.main_loop
                        )
                    
                    # 2. ìƒˆ ì„¸ì…˜ ìƒì„±
                    self.engine.history_manager.start_new_session(system_prompt=SYSTEM_PROMPT_RESP_ONLY)

                    return IdleState(self.engine)
                else:
                    logging.info("í‚¤ì›Œë“œ ë¶ˆì¼ì¹˜ -> ë‹¤ì‹œ Sleep")
                    return SleepState(self.engine)
            
            else:
                # ì¢…ë£Œ í‚¤ì›Œë“œ ê²€ì‚¬
                if any(kw in text for kw in self.engine.end_keywords):
                    logging.info(f"ðŸ‘‹ ì¢…ë£Œ í‚¤ì›Œë“œ ê°ì§€: '{text}' -> Sleep ì „í™˜")

                    # ì¢…ë£Œ ì‚¬ìš´ë“œ ìž¬ìƒ
                    if self.engine.websocket:
                        asyncio.run_coroutine_threadsafe(
                            self.engine.websocket.send(json.dumps({"type": "play_audio", "file_to_play": str(SLEEP_FILE)})),
                            self.engine.main_loop
                        )
                    self.engine.history_manager.end_session()
                    return SleepState(self.engine)
                
            # ì¼ë°˜ ëŒ€í™” --> ThinkingStateë¡œ ì§„í–‰
            return ThinkingState(self.engine, text)
            
        except queue.Empty:
            # ì•„ì§ ê²°ê³¼ê°€ ë„ì°©í•˜ì§€ ì•ŠìŒ -> íƒ€ìž„ì•„ì›ƒ ì²´í¬
            pass

        # 2. íƒ€ìž„ì•„ì›ƒ ì²˜ë¦¬
        # ë„¤íŠ¸ì›Œí¬ ì§€ì—° ë“±ìœ¼ë¡œ STT ê²°ê³¼ê°€ ì˜ì›ížˆ ì•ˆ ì˜¬ ê²½ìš°ë¥¼ ëŒ€ë¹„
        if time.time() - self.start_time > STT_WAIT_TIMEOUT_SECONDS:
            logging.warning(f"âš ï¸ STT ê²°ê³¼ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ ({STT_WAIT_TIMEOUT_SECONDS}s)")
            return self._handle_failure()
                    
        return None # ê³„ì† ëŒ€ê¸°

    def _handle_failure(self):
        """ê²°ê³¼ ìˆ˜ì‹  ì‹¤íŒ¨(ë¹ˆ ê°’, íƒ€ìž„ì•„ì›ƒ) ì‹œ ë¶„ê¸° ì²˜ë¦¬"""
        if self.mode == "WAKEWORD":
            logging.info("ë‹¨ìˆœ ì†ŒìŒ ë˜ëŠ” ì¸ì‹ ì‹¤íŒ¨ -> Sleep ë³µê·€")
            return SleepState(self.engine) 
        if self.was_interruption:
            # ì¸í„°ëŸ½ì…˜ì´ì—ˆëŠ”ë° ì‹¤íŒ¨í•¨ -> "ë­ë¼ê³  í•˜ì…¨ì£ ?" ë³µêµ¬ ì‹œë„
            logging.info("ì¸í„°ëŸ½ì…˜ ì¸ì‹ ì‹¤íŒ¨ -> Hesitating(ë³µêµ¬) ëª¨ë“œ ì§„ìž…")
            return HesitatingState(self.engine)
        else:
            # ê·¸ëƒ¥ í˜¼ìž ë§í•˜ë‹¤ ë©ˆì¶˜ ê²ƒ -> ë¬´ì‹œí•˜ê³  ëŒ€ê¸°
            logging.info("ë‹¨ìˆœ ì†ŒìŒ ë˜ëŠ” ì¸ì‹ ì‹¤íŒ¨ -> Idle ë³µê·€")
            return IdleState(self.engine)

    def on_exit(self):
        pass


class HesitatingState(ConversationState):
    """
    ì¸í„°ëŸ½ì…˜ì¸ ì¤„ ì•Œì•˜ëŠ”ë° STTê°€ ë¹„ì—ˆì„ ë•Œ.
    ìž ì‹œ(ì˜ˆ: 2~3ì´ˆ) ê¸°ë‹¤ë¦¬ë©°, ë¡œë´‡ì´ "ë„¤?" í•˜ê³  ë˜ë¬¼ì„ì§€ ê°„ì„ ë³´ëŠ” ìƒíƒœ.
    """
    def __init__(self, engine):
        super().__init__(engine)
        self.start_time = 0.0
        self.has_llm_result = False
        self.generated_text = None

    def on_enter(self):
        logging.info("STATE: [Hesitating] ëˆˆì¹˜ ë³´ëŠ” ì¤‘... (ë³µêµ¬ ë©˜íŠ¸ ìƒì„± ì‹œìž‘)")
        self.start_time = time.time()
        
        # 1. LLMì— "ë„¤?" ê°™ì€ ë³µêµ¬ ë©˜íŠ¸ ìƒì„± ìš”ì²­
        self.engine.llm_manager.request_hesitation()

    def update(self, chunk):
        # 1. ì‚¬ìš©ìžê°€ ë‹¤ì‹œ ë§í•˜ëŠ”ì§€ ê°ì‹œ (VAD On)
        if chunk is not None:
             self.engine.stt_pre_buffer.append(chunk) # ë²„í¼ë§ ì¶”ê°€
             if self.engine.vad_processor.process(chunk):
                logging.info("ðŸ—£ï¸ ì‚¬ìš©ìžê°€ ë‹¤ì‹œ ë§í•¨ -> ì¦‰ì‹œ ë“£ê¸°")
                
                # ìƒì„± ì¤‘ì´ë˜ LLM ì·¨ì†Œ
                self.engine.llm_manager.cancel()

                return ListeningState(self.engine, is_interruption=True)
        
        # 2. LLM ê²°ê³¼ í™•ì¸ (Non-blocking)
        if not self.has_llm_result:
            try:
                result_pkg = self.engine.llm_manager.response_queue.get_nowait()
                if result_pkg and result_pkg.get("text"):
                    self.generated_text = result_pkg["text"]
                    self.has_llm_result = True
                    logging.info(f"ðŸ¤” ë©˜íŠ¸ ì¤€ë¹„ë¨: {self.generated_text}")
            except queue.Empty:
                pass

        # 3. ëˆˆì¹˜ ë³´ê¸° íƒ€ìž„ì•„ì›ƒ ì²˜ë¦¬
        # ìƒí™©: ì‚¬ìš©ìžê°€ ì¡°ìš©í•¨ + LLM ë©˜íŠ¸ë„ ì¤€ë¹„ë¨ -> ë§í•˜ê¸° ì‹œë„
        elapsed = time.time() - self.start_time
        
        if elapsed > 2.0:
            if self.has_llm_result:
                # ë©˜íŠ¸ê°€ ì¤€ë¹„ëìœ¼ë©´ -> Speakingìœ¼ë¡œ ë„˜ì–´ê°€ì„œ ë§í•¨
                # ì´ë•Œ Historyì— ì¶”ê°€í• ì§€ ë§ì§€ëŠ” ì •ì±… ê²°ì • (ì—¬ê¸°ì„  ì•ˆ í•¨)
                logging.info("â³ ì¹¨ë¬µ ì§€ì† -> ë³µêµ¬ ë©˜íŠ¸ ë°œí™”")
                
                return ThinkingState(self.engine, pre_generated_text=self.generated_text)
            
            elif elapsed > 10.0:
                # 10ì´ˆê°€ ì§€ë‚¬ëŠ”ë°ë„ LLMì´ ì•ˆ ë‚˜ì˜¤ê±°ë‚˜ ì‚¬ìš©ìžê°€ ì¡°ìš©í•˜ë©´
                logging.info("â³ ë„ˆë¬´ ì˜¤ëž˜ ê±¸ë¦¼ -> ê·¸ëƒ¥ ëŒ€ê¸°(Idle)ë¡œ ë³µê·€")
                self.engine.llm_manager.cancel()
                return IdleState(self.engine)

        return None

    def on_exit(self):
        pass


class ThinkingState(ConversationState):
    """
    LLM ìƒì„± ~ TTS ë²„í¼ë§ ~ ìž¬ìƒ ì‹œìž‘ ì§ì „ê¹Œì§€.
    ë¼ì–´ë“¤ê¸° ë¶ˆê°€ (VAD ë¬´ì‹œ)
    """
    def __init__(self, engine, query_text=None, pre_generated_text=None):
        super().__init__(engine)
        self.query_text = query_text
        self.pre_generated_text = pre_generated_text
        self.step = "LLM" # LLM | TTS_BUFFER
        self.led_task = None

    def on_enter(self):
        logging.info("STATE: [Thinking] ë‹µë³€ ìƒì„± ë° ì¤€ë¹„")
        if self.pre_generated_text:
            # 1. ì´ë¯¸ í…ìŠ¤íŠ¸ê°€ ìžˆìœ¼ë©´ LLM ìƒëžµí•˜ê³  ë°”ë¡œ TTS
            logging.info(f"ðŸš€ ë¯¸ë¦¬ ìƒì„±ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©: {self.pre_generated_text}")
            self.engine.tts_manager.speak(self.pre_generated_text)
            self.step = "TTS_BUFFER"
            self.post_action = None
        else:
            if self.engine.main_loop:
                # LED: Thinking Effect On
                self.led_task = self.engine.main_loop.create_task(run_thinking_led_spin(233, 233, 50))
            self.engine.llm_manager.request_generation(self.query_text)

    def update(self, chunk):
        # ì˜¤ë””ì˜¤ ì²­í¬ ë¬´ì‹œ (ì¸í„°ëŸ½ì…˜ ë¶ˆê°€)

        if self.step == "LLM":
            try:
                result_pkg = self.engine.llm_manager.response_queue.get_nowait()

                if result_pkg:
                    self.text = result_pkg.get("text", "")
                    self.post_action = result_pkg.get("action")

                    if self.text:
                        logging.info(f"ðŸ¤– TTS ì¤€ë¹„: {self.text[:30]}...")
                        self.engine.tts_manager.speak(self.text)
                        self.step = "TTS_BUFFER"
                    else:
                        return IdleState(self.engine)
                else:
                    return IdleState(self.engine) # ì—ëŸ¬ ì²˜ë¦¬
            except queue.Empty:
                pass
        
        # 2. TTS ìž¬ìƒ ì‹œìž‘ ëŒ€ê¸°
        elif self.step == "TTS_BUFFER":
            if self.engine.tts_manager.playback_started_event.is_set():
                return SpeakingState(
                    self.engine, 
                    post_action=self.post_action
                )

        return None

    def on_exit(self):
        if not self.pre_generated_text:
            # LED: Thinking Effect Off
            if self.led_task and not self.led_task.done():
                self.led_task.cancel()


class SpeakingState(ConversationState):
    """
    ë¡œë´‡ì´ ë§í•˜ê³  ìžˆëŠ” ìƒíƒœ.
    ë¼ì–´ë“¤ê¸° ê°€ëŠ¥ (VAD ê°ì‹œ)
    """
    def __init__(self, engine, post_action=None):
        super().__init__(engine)
        self.post_action = post_action
    
    def on_enter(self):
        logging.info("STATE: [Speaking] ë°œí™” ì¤‘...")
        # LED: ë°œí™” ì¤‘ ì´íŽ™íŠ¸
        led_set_ring(50, 50, 233)
        self.engine.vad_processor.reset()
        self.engine.robot_finished_speaking = False

    def update(self, chunk):
        # 1. ë¼ì–´ë“¤ê¸° ê°ì§€
        if chunk is not None:
            self.engine.stt_pre_buffer.append(chunk) # ë²„í¼ë§ ì¶”ê°€
            if self.engine.vad_processor.process(chunk):
                logging.info("âš¡ ë¼ì–´ë“¤ê¸° ë°œìƒ!")
                self.engine.tts_manager.stop()
                return ListeningState(self.engine, is_interruption=True)

        # 2. ë¡œë´‡ ë™ìž‘ ì¢…ë£Œ í™•ì¸ (C++ ì‹œê·¸ë„)
        if self.engine.robot_finished_speaking:
            logging.info("âœ… ë¡œë´‡ ë°œí™” ë° ëª¨ì…˜ ì¢…ë£Œ (Signal Received)")
            self.engine.robot_finished_speaking = False

            # í›„ì† ì•¡ì…˜(ë…¸ëž˜)ì´ ìžˆë‹¤ë©´ ì²˜ë¦¬
            if self.post_action:
                return self._handle_post_action()
            
            return IdleState(self.engine)

        return None
    
    def _handle_post_action(self):
        """ë…¸ëž˜ ìž¬ìƒ ì „ ëª¨ì…˜ ìƒì„± í™•ì¸ ë° ëª…ë ¹ ì „ì†¡"""
        logging.info("ðŸŽµ í›„ì† ì•¡ì…˜(ìŒì•… ìž¬ìƒ) ì¤€ë¹„ ì¤‘...")
        motion_thread = self.post_action.get("motion_thread")

        # 1. ëª¨ì…˜ ìƒì„± ìŠ¤ë ˆë“œê°€ ìžˆë‹¤ë©´ ì™„ë£Œ ëŒ€ê¸° (Join)
        if motion_thread and motion_thread.is_alive():
            logging.info("âš™ï¸ ëª¨ì…˜ ìƒì„± ì™„ë£Œ ëŒ€ê¸° (Join)...")
            motion_thread.join()
            logging.info("âš™ï¸ ëª¨ì…˜ ìƒì„± ì™„ë£Œ.")

        # 2. ì›¹ì†Œì¼“ìœ¼ë¡œ ìž¬ìƒ ëª…ë ¹ ì „ì†¡
        audio_name = self.post_action.get("audio_name")
        if audio_name:
            if self.engine.websocket:
                asyncio.run_coroutine_threadsafe(
                    self.engine.websocket.send(json.dumps({"type": "play_audio_csv", "audio_name": audio_name})),
                    self.engine.main_loop
                )
            logging.info(f"ðŸš€ ìŒì•… ìž¬ìƒ ëª…ë ¹ ì „ì†¡: {audio_name}")

        # 3. ë…¸ëž˜ë¥¼ í‹€ì—ˆìœ¼ë‹ˆ ëŒ€ê¸°ë¡œ ë³µê·€
        # (ë§Œì•½ ë…¸ëž˜ ëë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì•¼ í•œë‹¤ë©´ 'MusicPlayingState' ê°™ì€ ìƒíƒœ í•„ìš”)
        return IdleState(self.engine)

    def on_exit(self):
        pass


# ==================================================================================
# 3. Context (Engine)
# ==================================================================================

class ConversationEngine:
    def __init__(self, websocket, main_loop):
        logging.info("ì´ˆê¸°í™” ì‹œìž‘")
        self.websocket = websocket
        self.main_loop = main_loop # asyncio loop (for websocket thread-safety)

        # 1. ì„¤ì • ë¡œë“œ
        self.sample_rate = AUDIO_CONFIG['SAMPLE_RATE']
        self.chunk_size = AUDIO_CONFIG['VAD_CHUNK_SIZE']

        # í‚¤ì›Œë“œ ì„¤ì •
        self.start_keyword = START_KEYWORD
        self.end_keywords = END_KEYWORDS
        self.active_timeout = ACTIVE_SESSION_TIMEOUT

        # 2. ë°ì´í„° í ì´ˆê¸°í™”
        self.mic_queue = queue.Queue()
        self.stt_audio_queue = queue.Queue()
        self.stt_result_queue = queue.Queue()

        # 3. ë²„í¼ ì´ˆê¸°í™”
        # Pre-buffer: ë°œí™” ê°ì§€ ì „ 0.5ì´ˆ ì •ë„ì˜ ì˜¤ë””ì˜¤ë¥¼ ì €ìž¥ (dequeë¡œ ìžë™ ê¸¸ì´ ê´€ë¦¬)
        pre_buffer_len = math.ceil(self.sample_rate * 0.5 / self.chunk_size)
        self.stt_pre_buffer = deque(maxlen=pre_buffer_len)

        # 4. ë„êµ¬(Tools) ì´ˆê¸°í™”
        self.vad_processor = VADProcessor(
            sample_rate=self.sample_rate,
            chunk_size=self.chunk_size,
            threshold=AUDIO_CONFIG['VAD_THRESHOLD'],
            consecutive_chunks=AUDIO_CONFIG['VAD_CONSECUTIVE_CHUNKS'],
            reset_interval=AUDIO_CONFIG['VAD_RESET_INTERVAL']
        )
        
        self.smart_turn_processor = SmartTurnProcessor(SMART_TURN_MODEL_PATH)

        # 5. ë§¤ë‹ˆì €(Managers) ì´ˆê¸°í™”
        self.history_manager = ConversationManager(openai_api_key=OPENAI_API_KEY)

        self.llm_manager = LLMManager(
            openai_api_key=OPENAI_API_KEY,
            conversation_manager=self.history_manager,
            main_loop=self.main_loop,
            websocket=self.websocket
        )
        
        self.tts_manager = TTSManager(
            openai_api_key=OPENAI_API_KEY,
            main_loop=self.main_loop,
            websocket=self.websocket
        )

        # 6. STT ìŠ¤íŠ¸ë¦¬ë¨¸ ì´ˆê¸°í™”
        self.stt_stop_event = threading.Event()
        self.stt_streamer = GoogleSTTStreamer(
            stt_result_queue=self.stt_result_queue,
            main_loop=self.main_loop,
            websocket=self.websocket,
            sample_rate=self.sample_rate,
            stt_audio_queue=self.stt_audio_queue,
            stt_stop_event=self.stt_stop_event
        )

        # 7. ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”
        self.mic_stream = MicrophoneStream(
            mic_audio_queue=self.mic_queue,
            sample_rate=self.sample_rate,
            chunk_size=self.chunk_size,
            channels=AUDIO_CONFIG['CHANNELS'],
            dtype=AUDIO_CONFIG['AUDIO_DTYPE'],
            device_idx=find_input_device()
        )

        # 8. ìƒíƒœ ì´ˆê¸°í™”
        self._current_state = SleepState(self)
        self._is_running = False
        self.robot_finished_speaking = False

    def on_robot_finished(self):
        """C++ë¡œë¶€í„° ë§í•˜ê¸° ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ """
        logging.info("ðŸ¤– Robot finished speaking signal received")
        self.robot_finished_speaking = True

    async def start(self):
        logging.info("ðŸš€ ConversationEngine ì‹œìž‘")
        self._is_running = True

        # ë§ˆì´í¬ ìº¡ì²˜ ì‹œìž‘ (Background Thread inside sounddevice)
        self.mic_stream.start()

        # ì´ˆê¸° ìƒíƒœ ì§„ìž…
        self._current_state.on_enter()
        
        try:
            await self._loop()
        except asyncio.CancelledError:
            logging.info("ì—”ì§„ ìž‘ì—… ì·¨ì†Œë¨")
        except KeyboardInterrupt:
            logging.info("í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ ê°ì§€")
        finally:
            self.stop()
    
    def stop(self):
        """ì—”ì§„ ì¢…ë£Œ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logging.info("ðŸ›‘ ConversationEngine ì¢…ë£Œ ì¤‘...")
        self._is_running = False
        
        # ë§ˆì´í¬ ì¤‘ì§€
        if self.mic_stream:
            self.mic_stream.stop()
        
        # ë§¤ë‹ˆì €/ìŠ¤ë ˆë“œ ì •ë¦¬
        self.stt_stop_event.set()
        self.stt_audio_queue.put(None)
        self.llm_manager.cancel()
        self.tts_manager.stop()
        
        logging.info("âœ… ì¢…ë£Œ ì™„ë£Œ")

    async def _loop(self):
        """ë©”ì¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë£¨í”„"""
        while self._is_running:
            await asyncio.sleep(0.01)

            try:
                # 1. ë§ˆì´í¬ ìž…ë ¥ (Blocking w/ Timeout)
                chunk = self.mic_queue.get_nowait()
            except queue.Empty:
                chunk = None # ë°ì´í„°ê°€ ì—†ì–´ë„ updateëŠ” í˜¸ì¶œí•´ì•¼ í•¨ (íƒ€ì´ë¨¸ ë¡œì§ ë“±)

            # 2. í˜„ìž¬ ìƒíƒœ ì—…ë°ì´íŠ¸
            next_state = self._current_state.update(chunk)

            # 3. ìƒíƒœ ì „ì´
            if next_state:
                self._transition(next_state)

    def _transition(self, new_state):
        prev_name = self._current_state.__class__.__name__
        next_name = new_state.__class__.__name__
        logging.info(f"ðŸ”„ ìƒíƒœ ì „ì´: {prev_name} -> {next_name}")

        self._current_state.on_exit()
        self._current_state = new_state
        self._current_state.on_enter()

async def test():
    logging.info("test ì‹œìž‘")
    engine = ConversationEngine(websocket=None, main_loop=asyncio.get_running_loop())
    await engine.start()

if __name__ == "__main__":
    asyncio.run(test())