import os
import json
import time
import wave
import base64
import asyncio
import logging
from typing import List, Dict, Any

import websockets
from openai import AsyncOpenAI

from config import (
    SLEEP_FILE, AWAKE_FILE, ACTIVE_SESSION_TIMEOUT, START_KEYWORD, END_KEYWORDS,
    TTS_MODEL, VOICE, REALTIME_MODEL, RESPONSES_MODEL, AUDIO_CONFIG
)
from prompts import REALTIME_PROMPT
from audio_processor import AudioProcessor
from conversation_manager import ConversationManager

logger = logging.getLogger(__name__)

# ==================================================================================
# TTS ê´€ë ¨
# ==================================================================================

async def save_tts_to_file(response_text: str, client: AsyncOpenAI, filename: str = "output.mp3"):
    """í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ TTS ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ ì €ì¥"""
    try:
        async with client.audio.speech.with_streaming_response.create(
            model=TTS_MODEL,
            voice=VOICE,
            input=response_text,
            instructions="Speak in a positive tone.",
            response_format="wav" 
        ) as tts_response:
            
            logging.info(f"ğŸ’¾ TTS íŒŒì¼ ì €ì¥ ì‹œì‘: {filename}")
            
            with open(filename, "wb") as f:
                async for audio_chunk in tts_response.iter_bytes(chunk_size=4096):
                    if audio_chunk:
                        f.write(audio_chunk)
                        
        logging.info("âœ… TTS íŒŒì¼ ì €ì¥ ì™„ë£Œ")

    except asyncio.CancelledError:
        logging.info("ğŸ›‘ TTS ì²˜ë¦¬ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        # íŒŒì¼ì´ ì“°ë‹¤ ë§Œ ìƒíƒœë¼ë©´ ì‚­ì œí•˜ëŠ” ë¡œì§ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        if os.path.exists(filename):
            os.remove(filename)
        raise
    except Exception as e:
        logging.error(f"âŒ TTS ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

async def handle_tts_stream(response_stream, client: AsyncOpenAI, websocket, conversation_log: List[Dict[str, Any]], responses_start_time=None):
    """(ì‚¬ìš©ë˜ì§€ ì•ŠìŒ - ì°¸ê³ ìš©) Responses APIì˜ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼ì„ ë°›ì•„ TTS ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜ í›„ ì „ì†¡"""
    await websocket.send(json.dumps({"type": "responses_stream_start"}))
    
    full_response_text = ""
    sentence_buffer = ""
    try:
        async for event in response_stream:
            if event.type == "response.output_text.delta":
                text_chunk = event.delta
                sentence_buffer += text_chunk
                full_response_text += text_chunk
                
                if any(p in sentence_buffer for p in ".?!\n"):
                    async with client.audio.speech.with_streaming_response.create(
                        model=TTS_MODEL, voice=VOICE, input=sentence_buffer, response_format="pcm"
                    ) as tts_response:
                        async for audio_chunk in tts_response.iter_bytes(chunk_size=4096):
                            await websocket.send(json.dumps({
                                "type": "responses_audio_chunk", 
                                "data": base64.b64encode(audio_chunk).decode('utf-8')
                            }))
                    sentence_buffer = ""
            
            if event.type == "response.completed":
                message = f"(ì†Œìš”ì‹œê°„: {time.time() - responses_start_time:.2f}ì´ˆ)" if responses_start_time else ""
                logger.info(f"OpenAI ì‘ë‹µ ì™„ë£Œ: '{full_response_text}' {message}")

        if sentence_buffer.strip():
            async with client.audio.speech.with_streaming_response.create(
                model=TTS_MODEL, voice=VOICE, input=sentence_buffer, response_format="pcm"
            ) as tts_response:
                async for audio_chunk in tts_response.iter_bytes(chunk_size=4096):
                    await websocket.send(json.dumps({
                        "type": "responses_audio_chunk", 
                        "data": base64.b64encode(audio_chunk).decode('utf-8')
                    }))

    except asyncio.CancelledError:
        logger.info("TTS ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        raise
    finally:
        await websocket.send(json.dumps({"type": "responses_stream_end"}))
        if full_response_text:
            conversation_log.append({"role": "assistant", "content": full_response_text})

async def handle_tts_oneshot(response_text: str, client: AsyncOpenAI, websocket, realtime_start_event: asyncio.Event):
    """ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ í•œ ë²ˆì— TTS ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    try:
        if realtime_start_event.is_set():
            await websocket.send(json.dumps({"type": "responses_stream_start"}))
        else:
            await websocket.send(json.dumps({"type": "responses_only"}))
        async with client.audio.speech.with_streaming_response.create(
            model=TTS_MODEL, voice=VOICE, input=response_text, response_format="pcm"
        ) as tts_response:
            async for audio_chunk in tts_response.iter_bytes(chunk_size=4096):
                await websocket.send(json.dumps({
                    "type": "responses_audio_chunk", 
                    "data": base64.b64encode(audio_chunk).decode('utf-8')
                }))
    except asyncio.CancelledError:
        logger.info("TTS ì²˜ë¦¬ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        raise
    finally:
        await websocket.send(json.dumps({"type": "responses_stream_end"}))

# ==================================================================================
# Unified API Pipeline (Realtime + Responses)
# ==================================================================================

async def run_realtime_task(websocket, realtime_connection, item_ids_to_manage: list, user_text: str, realtime_start_event: asyncio.Event):
    """(Task 1) Realtime APIë¥¼ í˜¸ì¶œí•˜ê³  ì˜¤ë””ì˜¤ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤."""
    logger.info("âš¡ï¸ Realtime Task ì‹œì‘...")
    try:
        if item_ids_to_manage:
            logger.info(f"ì´ì „ Realtime ëŒ€í™” ì•„ì´í…œ {len(item_ids_to_manage)}ê°œ ì‚­ì œ ì¤‘...")
            delete_tasks = [realtime_connection.conversation.item.delete(item_id=item_id) for item_id in item_ids_to_manage]
            await asyncio.gather(*delete_tasks, return_exceptions=True)
            item_ids_to_manage.clear()

        await realtime_connection.session.update(session={"type": "realtime", "instructions": REALTIME_PROMPT, "audio": {"output": {"voice": VOICE}}})
        await realtime_connection.conversation.item.create(
            item={"type": "message", "role": "user", "content": [{"type": "input_text", "text": user_text}]}
        )

        realtime_start_time = time.time()
        await realtime_connection.response.create()

        with wave.open("output/audio/realtime.wav", "wb") as wf:
            wf.setnchannels(AUDIO_CONFIG['CHANNELS'])
            wf.setsampwidth(2)
            wf.setframerate(AUDIO_CONFIG['SAMPLE_RATE'])

            async for event in realtime_connection:

                if event.type == "conversation.item.added":
                    item_ids_to_manage.append(event.item.id)

                elif event.type == "response.output_audio.delta":
                    await websocket.send(json.dumps({"type": "realtime_audio_chunk", "data": event.delta}))
                    bytes_data = base64.b64decode(event.delta)
                    wf.writeframes(bytes_data)

                elif event.type == "response.created":
                    realtime_start_event.set()
                    await websocket.send(json.dumps({"type": "realtime_stream_start"}))

                elif event.type == "response.done":
                    await websocket.send(json.dumps({"type": "realtime_stream_end"}))
                    transcript = event.response.output[0].content[0].transcript if event.response.output[0].content[0].type != "text" else "[Realtime ì‘ë‹µ ì—†ìŒ]"
                    logger.info(f"âš¡ï¸ Realtime API ë‹µë³€ ì™„ë£Œ: '{transcript}' (ì†Œìš”ì‹œê°„: {time.time() - realtime_start_time:.2f}ì´ˆ)")
                    wf.close()
                    break

                elif event.type == "error":
                    logger.error(f"Realtime API ì˜¤ë¥˜ ì´ë²¤íŠ¸: {event}")
    
    except asyncio.CancelledError:
        logger.info("âš¡ï¸ Realtime Taskê°€ ì™¸ë¶€ì—ì„œ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"âš¡ï¸ Realtime Task ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
    finally:
        logger.info("âš¡ï¸ Realtime Task ì¢…ë£Œ.")

async def run_responses_task(websocket, openai_client: AsyncOpenAI, manager: ConversationManager, realtime_start_event: asyncio.Event):
    """(Task 2) Responses APIë¥¼ í˜¸ì¶œí•˜ê³ , TTSë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤."""
    logger.info("ğŸ§  Responses Task ì‹œì‘...")
    responses_start_time = time.time()
    current_log = manager.get_current_log()

    try:
        response = await openai_client.responses.create(
            model=RESPONSES_MODEL,
            input=current_log,
            tools=[
                {
                    "type": "web_search",
                    "user_location": {
                        "type": "approximate",
                        "country": "KR",
                    }
                }
            ],
            reasoning={"effort": "none"},
            text = {"verbosity": "low"},
        )
        # logging.info(f"ğŸ§  Responses Query: \n{response}")
        # response_id = response.id

        # response_item = await openai_client.responses.input_items.list(response_id)
        # print(response_item.data)

        response_text = response.output_text.strip()
        logger.info(f"ğŸ§  Responses API ë‹µë³€ ìƒì„± ì™„ë£Œ: '{response_text}' (ì†Œìš”ì‹œê°„: {time.time() - responses_start_time:.2f}ì´ˆ)")

        await handle_tts_oneshot(response_text, openai_client, websocket, realtime_start_event)
        manager.add_message("assistant", response_text)

    except asyncio.CancelledError:
        logger.info("ğŸ§  Responses Taskê°€ ì™¸ë¶€ì—ì„œ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ğŸ§  Responses Task ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
    finally:
        logger.info("ğŸ§  Responses Task ì¢…ë£Œ.")

async def unified_active_pipeline(websocket, openai_client: AsyncOpenAI, manager: ConversationManager):
    """ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•´ Realtime APIì™€ Responses APIë¥¼ ë™ì‹œì— í˜¸ì¶œí•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ ì‘ë‹µí•˜ëŠ” í†µí•© íŒŒì´í”„ë¼ì¸"""
    logger.info("ğŸ¤– Unified Active Pipeline ì‹œì‘...")
    active_response_tasks = []
    stt_result_queue = asyncio.Queue()
    main_loop = asyncio.get_running_loop()

    async with openai_client.realtime.connect(model=REALTIME_MODEL) as realtime_connection:
        realtime_item_ids_to_manage = []
        try:
            with AudioProcessor(stt_result_queue, main_loop, websocket, config=AUDIO_CONFIG) as audio_processor:
                while True:
                    try:
                        user_text = await asyncio.wait_for(stt_result_queue.get(), timeout=ACTIVE_SESSION_TIMEOUT)
                        realtime_start_event = asyncio.Event()

                        if active_response_tasks:
                            logger.info(f"ì‚¬ìš©ì ì¸í„°ëŸ½ì…˜ ê°ì§€: '{user_text}'. ì´ì „ ì‘ë‹µ íƒœìŠ¤í¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                            for task in active_response_tasks: task.cancel()
                            await asyncio.gather(*active_response_tasks, return_exceptions=True)
                            active_response_tasks = []

                        if any(kw in user_text for kw in END_KEYWORDS):
                            await websocket.send(json.dumps({"type": "play_audio", "file_to_play": str(SLEEP_FILE)}))
                            logger.info(f"ì¢…ë£Œ í‚¤ì›Œë“œ ê°ì§€: '{user_text}' - ì„¸ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                            break

                        manager.add_message("user", user_text)

                        realtime_task = asyncio.create_task(
                            run_realtime_task(websocket, realtime_connection, realtime_item_ids_to_manage, user_text, realtime_start_event)
                        )
                        responses_task = asyncio.create_task(
                            run_responses_task(websocket, openai_client, manager, realtime_start_event)
                        )
                        active_response_tasks = [responses_task, realtime_task]
                        
                    except asyncio.TimeoutError:
                        logger.info(f"â° {ACTIVE_SESSION_TIMEOUT}ì´ˆ ë™ì•ˆ ì…ë ¥ì´ ì—†ì–´ Active ì„¸ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        await websocket.send(json.dumps({"type": "play_audio", "file_to_play": str(SLEEP_FILE)}))
                        break
        except Exception as e:
            logger.error(f"Unified Active Pipelineì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        finally:
            if active_response_tasks:
                for task in active_response_tasks: task.cancel()
                await asyncio.gather(*active_response_tasks, return_exceptions=True)
            logger.info("ğŸ¤– Unified Active Pipeline ì¢…ë£Œ.")

# ==================================================================================
# Sleep ëª¨ë“œ
# ==================================================================================

async def wakeword_detection_loop(websocket):
    """START_KEYWORDë¥¼ ê°ì§€í•  ë•Œê¹Œì§€ VAD-STT ë£¨í”„ë¥¼ ì‹¤í–‰ (Sleep ëª¨ë“œ)"""
    logger.info(f"ğŸ’¤ Sleep ëª¨ë“œ ì‹œì‘. '{START_KEYWORD}' í˜¸ì¶œ ëŒ€ê¸° ì¤‘...")
    keyword_queue = asyncio.Queue()
    main_loop = asyncio.get_running_loop()

    try:
        with AudioProcessor(keyword_queue, main_loop, websocket, config=AUDIO_CONFIG) as audio_processor:
            while True:
                stt_result = await keyword_queue.get()
                logger.info(f"[Sleep Mode] STT ê²°ê³¼: {stt_result}")
                if START_KEYWORD in stt_result:
                    await websocket.send(json.dumps({"type": "play_audio", "file_to_play": str(AWAKE_FILE)}))
                    return
                # í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
                # await asyncio.sleep(1)
                # await websocket.send(json.dumps({"type": "play_audio", "file_to_play": "test_audio.wav"}))
                # await websocket.send(json.dumps({"type": "play_music", "title": "ê°€ê¹Œìš´ ë“¯ ë¨¼ ê·¸ëŒ€ì—¬", "artist": "ì¹´ë”ê°€ë“ "}))
                # return
    except Exception as e:
        logger.error(f"Wakeword detection loopì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
    finally:
        logger.info("ğŸ’¤ Sleep ëª¨ë“œ ì¢…ë£Œ.")