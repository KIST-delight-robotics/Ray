import asyncio
import base64
import wave
import json
import websockets
from openai import AsyncOpenAI
import logging
import sounddevice as sd
import queue
from google.cloud import speech, texttospeech
from google.api_core import exceptions
import os
import functools
import time
import re
from pathlib import Path

# --- ë¡œê¹… ì„¤ì • ---
logging.basicConfig(level=logging.INFO, format='[%(asctime)s] [%(levelname)s] %(message)s')

# --- ì„¤ì • ---
# OpenAI API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# Google STT, TTS ì¸ì¦ ì •ë³´ ì„¤ì •
# GOOGLE_APPLICATION_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ì— Google Cloud API í‚¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •í•´ì•¼ í•¨.

# --- ë””ë ‰í† ë¦¬ ì„¤ì • ---
PROJECT_ROOT = Path(__file__).resolve().parent.parent
ASSETS_DIR = PROJECT_ROOT / "assets"
CONFIG_DIR = PROJECT_ROOT / "config"
OUTPUT_DIR = PROJECT_ROOT / "output"

# ê²½ë¡œ ì •ì˜
ASSETS_AUDIO_DIR = ASSETS_DIR / "audio"
MUSIC_DIR = ASSETS_AUDIO_DIR / "music"
OUTPUT_AUDIO_DIR = OUTPUT_DIR / "audio"

# ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ì„ ê²½ìš°)
OUTPUT_AUDIO_DIR.mkdir(parents=True, exist_ok=True)

COMMAND_CONFIG_FILE = str(CONFIG_DIR / "ray_conversation.json")
LOG_FILE = str(OUTPUT_DIR / "conversation_log.json")
OUTPUT_GPT_FILE = str(OUTPUT_AUDIO_DIR / "output_gpt.wav")
OUTPUT_TTS_FILE = str(OUTPUT_AUDIO_DIR / "output_tts.wav")
AWAKE_FILE = str(ASSETS_AUDIO_DIR / "awake.wav")
FINISH_FILE = str(ASSETS_AUDIO_DIR / "finish.wav")

# Load command configuration
with open(COMMAND_CONFIG_FILE, encoding="utf-8") as f:
    cfg = json.load(f)["Kor"]

# ì˜¤ë””ì˜¤ ì„¤ì •
CHANNELS = 1
SAMPLE_RATE = 24000
VOICE = "ash"

# --- ì „ì—­ ë³€ìˆ˜ ---
openai_connection = None
openai_lock = asyncio.Lock()
ray_mode = "sleep"
# ì‹œê°„ ì¸¡ì •ìš© ì „ì—­ ë³€ìˆ˜
stt_first_attempt_flag = True  # STT ì²« ì‹œë„ ì—¬ë¶€ í”Œë˜ê·¸
STT_READY_TIME = 0  # STT ì¤€ë¹„ ì‹œê°„ (í”„ë¡œê·¸ë¨ ì‹œì‘ í›„ ìŒì„± ì…ë ¥ ëŒ€ê¸°ê¹Œì§€ì˜ ì‹œê°„ ì¸¡ì •ìš©)
STT_DONE_TIME = 0  # STT ì™„ë£Œ ì‹œê°„ (ì‚¬ìš©ì ì…ë ¥ ì™„ë£Œ í›„ ìŒì„± ì¶œë ¥ê¹Œì§€ì˜ ì‹œê°„ ì¸¡ì •ìš©)
GPT_RESPONSE_TIME = 0  # GPT ì‘ë‹µ ì‹œê°„ (GPT ì‘ë‹µ ìƒì„±ì— ê±¸ë¦° ì‹œê°„)
GPT_RESPONSE_TEXT = ""

# --- STT ê¸°ëŠ¥ (ê¸°ì¡´ push_to_talk_app.pyì—ì„œ ê°€ì ¸ì˜´) ---
async def run_stt(timeout_sec: float = 5.0):
    """
    timeout_sec ì´ˆ ì•ˆì— ìµœì¢… STT ê²°ê³¼(final_text)ë¥¼ ëª» ì–»ìœ¼ë©´
    ë¹ˆ ë¬¸ìì—´ì„ ë¦¬í„´í•˜ê³  ì¦‰ì‹œ ì¢…ë£Œí•©ë‹ˆë‹¤.
    """
    global STT_READY_TIME, STT_DONE_TIME, stt_first_attempt_flag
    q_audio = queue.Queue()
    recording_done = asyncio.Event()

    def callback(indata, frames, time_info, status):
        if status:
            logging.warning(f"[ì˜¤ë””ì˜¤ ìƒíƒœ] {status}")
        q_audio.put(bytes(indata))

    input_device_index = None
    for idx, dev in enumerate(sd.query_devices()):
        if dev['max_input_channels'] > 0:
            input_device_index = idx
            break

    if input_device_index is None:
        logging.error("[ì˜¤ë¥˜] ì…ë ¥ ê°€ëŠ¥í•œ ë§ˆì´í¬ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return ""

    device_info = sd.query_devices(input_device_index, 'input')
    stt_sample_rate = int(device_info['default_samplerate'])

    stt_client = speech.SpeechClient()
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=stt_sample_rate,
        language_code="ko-KR",
    )
    streaming_config = speech.StreamingRecognitionConfig(
        config=config,
        interim_results=True,
        single_utterance=True,
    )

    def audio_generator():
        while not recording_done.is_set():
            chunk = q_audio.get()
            if chunk is None:
                break
            yield speech.StreamingRecognizeRequest(audio_content=chunk)

    final_text = ""

    try:
        with sd.InputStream(samplerate=stt_sample_rate, channels=CHANNELS, dtype="int16", callback=callback):
            logging.info("ğŸ™ï¸ STT ì‹œì‘: ë§í•˜ì„¸ìš”...")
            if stt_first_attempt_flag:
                STT_READY_TIME = time.time() * 1000
            responses = stt_client.streaming_recognize(streaming_config, audio_generator(), timeout=timeout_sec)

            for response in responses:
                if not response.results or not response.results[0].alternatives:
                    continue
                result = response.results[0]
                transcript = result.alternatives[0].transcript

                if result.is_final:
                    final_text += transcript
                    logging.info(f"[âœ… ìµœì¢… ì¸ì‹ ê²°ê³¼] {final_text}")
                    STT_DONE_TIME = time.time() * 1000
                    recording_done.set()
                    return final_text
                else:
                    logging.info(f"[ğŸ“ ì¤‘ê°„ ì¸ì‹] {transcript}")

    except exceptions.DeadlineExceeded:
        logging.warning(f"[STT] íƒ€ì„ì•„ì›ƒ({timeout_sec}s) ë°œìƒ.")
    except Exception as e:
        logging.error(f"STT ì²˜ë¦¬ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        logging.info("ğŸ™ï¸ STT ì¢…ë£Œ.")
        q_audio.put(None)
    
    return final_text

# --- TTS ê¸°ëŠ¥ ---
async def run_tts(text, output_file=OUTPUT_TTS_FILE):
    """
    Google TTSë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    :param text: ë³€í™˜í•  í…ìŠ¤íŠ¸
    :param output_file: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    :return: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    logging.info(f"TTS ìƒì„± ìš”ì²­: '{text}' -> {output_file}")
    tts_client = texttospeech.TextToSpeechClient()
    synthesis_input = texttospeech.SynthesisInput(text=text)
    voice = texttospeech.VoiceSelectionParams(language_code="ko-KR", ssml_gender=texttospeech.SsmlVoiceGender.MALE)
    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.LINEAR16, sample_rate_hertz=SAMPLE_RATE)
    
    response = await asyncio.to_thread(tts_client.synthesize_speech, input=synthesis_input, voice=voice, audio_config=audio_config)
    
    with open(output_file, "wb") as out:
        out.write(response.audio_content)
    logging.info(f"TTS íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file}")
    return output_file

# --- ë…¸ë˜ íŒŒì¼ ê²€ìƒ‰ ê¸°ëŠ¥ (C++ ë¡œì§ê³¼ ë™ì¼) ---
def normalize_string(input_str):
    return re.sub(r'\s+', '', input_str).lower()

def find_music_file(user_text):
    normalized_input = normalize_string(user_text)
    music_files = list(Path(MUSIC_DIR).glob("*.wav"))
    
    best_match = {'song_path': None, 'type': 'none', 'match_length': 0}

    for f_path in music_files:
        try:
            title, artist = f_path.stem.split('_', 1)
            norm_title = normalize_string(title)
            norm_artist = normalize_string(artist)
            
            # ì œëª© ìš°ì„  ê²€ìƒ‰
            if norm_title in normalized_input:
                if best_match['type'] != 'title' or len(norm_title) > best_match['match_length']:
                    best_match = {'song_path': str(f_path), 'title': title, 'artist': artist, 'type': 'title', 'match_length': len(norm_title)}
            # ì œëª©ì´ ì¼ì¹˜í•˜ì§€ ì•Šì„ ë•Œë§Œ ê°€ìˆ˜ ê²€ìƒ‰
            elif norm_artist in normalized_input and best_match['type'] != 'title':
                 if len(norm_artist) > best_match['match_length']:
                    best_match = {'song_path': str(f_path), 'title': title, 'artist': artist, 'type': 'artist', 'match_length': len(norm_artist)}
        except ValueError:
            logging.warning(f"íŒŒì¼ëª… í˜•ì‹ ì˜¤ë¥˜: {f_path.name}")
            continue
                
    return best_match if best_match['song_path'] else None

# --- GPT ì‘ë‹µ ìƒì„± ---
async def generate_gpt_response_audio(user_text: str) -> str:
    """
    GPT-4o-realtime APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì í…ìŠ¤íŠ¸ì— ëŒ€í•œ ìŒì„± ì‘ë‹µì„ ìƒì„±í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    ì„¸ì…˜ì€ ì „ì—­ `openai_connection`ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    global openai_connection, GPT_RESPONSE_TIME, GPT_RESPONSE_TEXT
    async with openai_lock:
        start_time = time.time() * 1000
        logging.info(f"ğŸ’¬ GPT ëŒ€í™” ì‹œì‘: {user_text}")
        log_conversation("user", user_text)
        await openai_connection.conversation.item.create(
            item={"type": "message", "role": "user", "content": [{"type": "input_text", "text": user_text}]}
        )
        await openai_connection.response.create()
        with wave.open(OUTPUT_GPT_FILE, "wb") as wf:
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(2)
            wf.setframerate(SAMPLE_RATE)
            accumulated_transcripts = {}
            async for event in openai_connection:
                if event.type == "response.audio.delta":
                    wf.writeframes(base64.b64decode(event.delta))
                elif event.type == "response.audio_transcript.delta":
                    accumulated_transcripts[event.item_id] = accumulated_transcripts.get(event.item_id, "") + event.delta
                elif event.type == "response.audio.done":
                    final_text = accumulated_transcripts.get(event.item_id, "")
                    logging.info(f"[ì‘ë‹µ] {final_text}")
                    GPT_RESPONSE_TIME = time.time() * 1000 - start_time
                    GPT_RESPONSE_TEXT = final_text
                    log_conversation("assistant", final_text)
                    break
    return OUTPUT_GPT_FILE

# --- ëŒ€í™” ë¡œê¹… ---
def log_conversation(role, text):
    try:
        with open(LOG_FILE, "a", encoding="utf-8") as f:
            log_entry = {"role": role, "content": text}
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
    except Exception as e:
        logging.error(f"âŒ ë¡œê·¸ íŒŒì¼ ì‘ì„± ì¤‘ ì˜¤ë¥˜: {e}")

# --- ë©”ì¸ í•¸ë“¤ëŸ¬ ---
async def chat_handler(websocket):
    global openai_connection, ray_mode, stt_first_attempt_flag, STT_READY_TIME, STT_DONE_TIME, GPT_RESPONSE_TIME, GPT_RESPONSE_TEXT
    if not openai_connection:
        logging.error("âŒ OpenAI ì „ì—­ ì„¸ì…˜ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    logging.info(f"âœ… C++ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨. í˜„ì¬ ëª¨ë“œ: {ray_mode}")
    
    try:
        # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ë¥¼ ê¸°ë‹¤ë¦¼
        async for message in websocket:
            data = json.loads(message)
            if data.get("request") != "next_action":
                continue

            file_to_play = None
            user_text = ""
            GPT_RESPONSE_TEXT = ""
            STT_DONE_TIME = 0

            # --- SLEEP ëª¨ë“œ ì²˜ë¦¬ ---
            if ray_mode == "sleep":
                logging.info("ğŸ’¤ Sleep ëª¨ë“œ ì‹œì‘. 'ë ˆì´' í˜¸ì¶œ ëŒ€ê¸° ì¤‘...")
                user_text = await run_stt(timeout_sec=5)
                if "ë ˆì´" in user_text:
                    logging.info("'ë ˆì´' í˜¸ì¶œ ê°ì§€!")
                    ray_mode = "active"
                    file_to_play = AWAKE_FILE
                else:
                    await websocket.send(json.dumps({"action": "sleep"}))
                    logging.info("ë ˆì´ í˜¸ì¶œ ì—†ìŒ. C++ í´ë¼ì´ì–¸íŠ¸ì— sleep ìœ ì§€ ì‹ í˜¸ ì „ì†¡.")
                    continue
            
            # --- ACTIVE ëª¨ë“œ ì²˜ë¦¬ ---
            elif ray_mode == "active":
                logging.info("âš¡ Active ëª¨ë“œ ì‹œì‘. ì‚¬ìš©ì ì§ˆë¬¸ ëŒ€ê¸° ì¤‘...")
                user_text = ""
                for attempt in range(3):
                    if attempt == 0:
                        stt_first_attempt_flag = True
                    else:
                        stt_first_attempt_flag = False
                    text = await run_stt(timeout_sec=5.0)
                    if text:
                        user_text = text
                        break
                    logging.info(f"ë¬µë¬µë¶€ë‹µ... ({attempt+1}/3)")

                if not user_text:
                    logging.info("ì‘ë‹µ ì—†ìŒ. Sleep ëª¨ë“œë¡œ ì „í™˜.")
                    ray_mode = "sleep"
                    file_to_play = FINISH_FILE

                # --- í‚¤ì›Œë“œ ì²˜ë¦¬ ---
                # ì¢…ë£Œ ëª…ë ¹ì–´
                elif any(kw in user_text for kw in cfg["conditions"].get("QUIT_PROGRAM", [])):
                    logging.info("ì¢…ë£Œ ëª…ë ¹ì–´ ê°ì§€. Sleep ëª¨ë“œë¡œ ì „í™˜.")
                    ray_mode = "sleep"
                    file_to_play = FINISH_FILE
                # ë…¸ë˜ ëª…ë ¹ì–´
                elif any(kw in user_text for kw in cfg["conditions"].get("SING_A_SONG", [])):
                    logging.info("ë…¸ë˜ ëª…ë ¹ì–´ ê°ì§€.")
                    norm_input = normalize_string(user_text)
                    if norm_input in ["ë…¸ë˜ë¶ˆëŸ¬ì¤˜", "ë…¸ë˜ë“¤ë ¤ì¤˜", "ë…¸ë˜í‹€ì–´ì¤˜"]:
                        response_text = "ë„¤, ë¬´ìŠ¨ ë…¸ë˜ ë¶ˆëŸ¬ì¤„ê¹Œìš”?"
                        file_to_play = await run_tts(response_text, OUTPUT_TTS_FILE)
                    else:
                        found_song_info = find_music_file(user_text)
                        if found_song_info:
                            title = found_song_info['title']
                            artist = found_song_info['artist']
                            response_text = f"{title} ë§ì”€ì´ì‹ ê°€ìš”? ì§€ê¸ˆ {title} by {artist}ë¥¼ ì¬ìƒí• ê²Œìš”."
                            file_to_play = await run_tts(response_text, OUTPUT_TTS_FILE)
                            await websocket.send(json.dumps({"action": "play_music", "file_to_play": file_to_play, "title": title, "artist": artist}))
                            logging.info(f"C++ í´ë¼ì´ì–¸íŠ¸ì— ì¬ìƒ ëª…ë ¹ ì „ì†¡: {found_song_info['song_path']}")
                            continue
                        else:
                            response_text = "ë§ì”€í•˜ì‹  ê³¡ì€ ëª©ë¡ì— ì—†ì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”!"
                            file_to_play = await run_tts(response_text, OUTPUT_TTS_FILE)

                # --- ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬ (GPT í˜¸ì¶œ) ---
                else:
                    file_to_play = await generate_gpt_response_audio(user_text)

            await websocket.send(json.dumps({
                "action": "play_audio",
                "file_to_play": str(file_to_play) if file_to_play else None,
                "stt_ready_time": STT_READY_TIME,
                "stt_done_time": STT_DONE_TIME,
                "gpt_response_time": GPT_RESPONSE_TIME,
                "user_text": user_text,
                "gpt_response_text": GPT_RESPONSE_TEXT
            }))
            logging.info(f"C++ í´ë¼ì´ì–¸íŠ¸ì— ì¬ìƒ ëª…ë ¹ ì „ì†¡: {file_to_play}")

    except websockets.exceptions.ConnectionClosed as e:
        logging.warning(f"â„¹ï¸ C++ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        logging.error(f"âŒ í•¸ë“¤ëŸ¬ ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
    finally:
        logging.info(f"ğŸ”Œ C++ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•¸ë“¤ëŸ¬ ì¢…ë£Œ: {websocket.remote_address}")

# --- Google STT API ì›Œë°ì—… ---
async def warm_up_stt_api():
    """
    ìµœì´ˆ 1íšŒ ì‹¤í–‰í•©ë‹ˆë‹¤.
    Google STT APIì— ë”ë¯¸ ìš”ì²­ì„ ë³´ë‚´ ì´ˆê¸° ì—°ê²° ì§€ì—°ì„ í•´ì†Œí•©ë‹ˆë‹¤.
    """
    logging.info("â˜ï¸ Google STT API ì›Œë°ì—… ì‹œì‘...")

    start_time = time.time()
    try:
        # ë”ë¯¸ ì˜¤ë””ì˜¤ ë°ì´í„° ìƒì„±
        def dummy_audio_generator():
            yield speech.StreamingRecognizeRequest(audio_content=b'\x00\x00')

        stt_client = speech.SpeechClient()
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="ko-KR",
        )
        streaming_config = speech.StreamingRecognitionConfig(
            config=config, single_utterance=True
        )

        def run_dummy_request():
            responses = stt_client.streaming_recognize(streaming_config, dummy_audio_generator())
            # ìš”ì²­ì´ ì‹¤ì œë¡œ ì „ì†¡ë˜ê³  ì²˜ë¦¬ë˜ë„ë¡ ìƒì„±ê¸°ë¥¼ ì†Œëª¨í•©ë‹ˆë‹¤.
            for _ in responses:
                pass
                
        await asyncio.to_thread(run_dummy_request)

        elapsed_time = time.time() - start_time
        logging.info("â˜ï¸ Google STT API ì›Œë°ì—… ì™„ë£Œ. ì†Œìš” ì‹œê°„: {:.2f}ì´ˆ".format(elapsed_time))
        return  # ì„±ê³µ ì‹œ í•¨ìˆ˜ ì¢…ë£Œ
    except Exception as e:
        logging.error(f"âŒ STT API ì›Œë°ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- OpenAI ì—°ê²° ì„¤ì • ---
async def setup_openai_connection():
    """
    OpenAI ì‹¤ì‹œê°„ ì„¸ì…˜ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì„¤ì •í•˜ê³ , ì „ì—­ ë³€ìˆ˜ openai_connectionì— ì €ì¥í•©ë‹ˆë‹¤.
    connection_managerë¥¼ ë°˜í™˜í•˜ì—¬ ì„¸ì…˜ ì¢…ë£Œ ì‹œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    """
    global openai_connection
    logging.info("ğŸ¤– OpenAI ì„¸ì…˜ ì—°ê²° ì‹œì‘...")
    
    openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
    connection_manager = openai_client.beta.realtime.connect(model="gpt-4o-realtime-preview")
    openai_connection = await connection_manager.__aenter__()
    await openai_connection.session.update(session={
        "instructions": "ë„ˆëŠ” ì• ë‹ˆë§¤íŠ¸ë¡œë‹‰ìŠ¤ ë¡œë´‡ì´ì•¼. ë„ˆì˜ ì´ë¦„ì€ ë ˆì´ì•¼. ë‚´ê°€ ë¬¼ì–´ë³´ëŠ” ê²ƒë“¤ì— ëŒ€í•´ ì˜ ëŒ€ë‹µí•´ì¤˜",
        "voice": VOICE
    })
    logging.info("âœ… OpenAI ì „ì—­ ì„¸ì…˜ì´ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return connection_manager

async def main():
    logging.info("ğŸš€ ì„œë²„ ì´ˆê¸°í™” ì‹œì‘: API ì›Œë°ì—… ë° ì—°ê²°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
    connection_manager = None
    try:
        # ì‹œê°„ì´ ì†Œìš”ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ì‘ì—…ë“¤ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
        results = await asyncio.gather(
            warm_up_stt_api(),
            setup_openai_connection(),
            return_exceptions=True
        )

        # gather ê²°ê³¼ ì²˜ë¦¬
        stt_warmup_success = False
        for result in results:
            if isinstance(result, Exception):
                logging.error(f"âŒ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {result}", exc_info=result)
            elif hasattr(result, '__aexit__'): # OpenAI connection_manager ì‹ë³„
                connection_manager = result
            else: # warm_up_stt_apiëŠ” ì„±ê³µ ì‹œ Noneì„ ë°˜í™˜í•˜ë¯€ë¡œ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                stt_warmup_success = True

        if not connection_manager:
            logging.error("âŒ OpenAI ì—°ê²°ì— ì‹¤íŒ¨í•˜ì—¬ ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        if not stt_warmup_success:
            logging.warning("âš ï¸ STT API ì›Œë°ì—…ì— ì‹¤íŒ¨í–ˆì§€ë§Œ ì„œë²„ëŠ” ê³„ì† ì‹¤í–‰ë©ë‹ˆë‹¤.")

        # WebSocket ì„œë²„ ì‹œì‘
        server = await websockets.serve(chat_handler, "127.0.0.1", 5000)
        logging.info("ğŸš€ í†µí•© WebSocket ì„œë²„ê°€ 127.0.0.1:5000 ì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        await server.wait_closed()
    finally:
        if connection_manager:
            logging.info("ğŸ”Œ OpenAI ì „ì—­ ì„¸ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            await connection_manager.__aexit__(None, None, None)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass